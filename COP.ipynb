{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04784754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from matplotlib import pyplot as plt\n",
    "from tools import *\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from scipy.optimize import LinearConstraint, NonlinearConstraint, Bounds, minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ee728a",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4aed84d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getObs(n):\n",
    "    obs = {}\n",
    "    for i in range(n):\n",
    "        try:\n",
    "            df = pd.read_csv(f'rocket-results/{i}.csv')\n",
    "        except:\n",
    "            print('Missing', i)\n",
    "        obs[i] = df\n",
    "    return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fffecbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeConfig():\n",
    "    configs = {}\n",
    "    with open('sample_list.pkl', 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "    configs.update(d)\n",
    "    with open('sample_list_100.pkl', 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "    configs.update(d)\n",
    "    with open('sample_list_200.pkl', 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "    configs.update(d)\n",
    "    with open('sample_list_300.pkl', 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "    configs.update(d)\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e8120dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = initializeConfig()\n",
    "obs = getObs(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca05fc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ff/y3gj2gld0zqfjtq_lhxz03t00000gn/T/ipykernel_30584/2135078581.py:5: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  data[i].append(obs[i].mean()['Stability Margin (cal)'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         3.734223\n",
       "1         7.875106\n",
       "2         2.509849\n",
       "3         7.372139\n",
       "4         8.753891\n",
       "5         7.977354\n",
       "6         7.539283\n",
       "7         8.558976\n",
       "8     32187.640000\n",
       "9         5.071216\n",
       "10       99.001530\n",
       "Name: 284, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {}\n",
    "for i in range(len(config)):\n",
    "    data[i] = list(config[i]['S'].values()) + list(config[i]['B'].values())\n",
    "    data[i].append(obs[i].max()['Altitude (ft)'])\n",
    "    data[i].append(obs[i].mean()['Stability Margin (cal)'])\n",
    "    data[i].append(obs[i].max()['Time (sec)'])\n",
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "df.iloc[284]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa42c786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Schord</th>\n",
       "      <th>Sspan</th>\n",
       "      <th>Ssweep</th>\n",
       "      <th>Stip</th>\n",
       "      <th>Bchord</th>\n",
       "      <th>Bspan</th>\n",
       "      <th>Bsweep</th>\n",
       "      <th>Btip</th>\n",
       "      <th>Schordspan</th>\n",
       "      <th>Schordsweep</th>\n",
       "      <th>...</th>\n",
       "      <th>SSweeptip</th>\n",
       "      <th>Bchordspan</th>\n",
       "      <th>Bchordsweep</th>\n",
       "      <th>Bchordtip</th>\n",
       "      <th>Bspansweep</th>\n",
       "      <th>BSpantip</th>\n",
       "      <th>BSweeptip</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Stability</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.465233</td>\n",
       "      <td>9.191411</td>\n",
       "      <td>6.313146</td>\n",
       "      <td>6.181568</td>\n",
       "      <td>4.253219</td>\n",
       "      <td>3.362766</td>\n",
       "      <td>2.004250</td>\n",
       "      <td>3.767645</td>\n",
       "      <td>86.998844</td>\n",
       "      <td>59.755399</td>\n",
       "      <td>...</td>\n",
       "      <td>39.025144</td>\n",
       "      <td>14.302581</td>\n",
       "      <td>8.524515</td>\n",
       "      <td>16.024619</td>\n",
       "      <td>6.739826</td>\n",
       "      <td>12.669711</td>\n",
       "      <td>7.551304</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>-5.121752</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.050903</td>\n",
       "      <td>2.807665</td>\n",
       "      <td>7.250966</td>\n",
       "      <td>4.202998</td>\n",
       "      <td>7.871765</td>\n",
       "      <td>6.329711</td>\n",
       "      <td>3.563606</td>\n",
       "      <td>6.148326</td>\n",
       "      <td>14.181241</td>\n",
       "      <td>36.623926</td>\n",
       "      <td>...</td>\n",
       "      <td>30.475799</td>\n",
       "      <td>49.826002</td>\n",
       "      <td>28.051867</td>\n",
       "      <td>48.398181</td>\n",
       "      <td>22.556595</td>\n",
       "      <td>38.917130</td>\n",
       "      <td>21.910210</td>\n",
       "      <td>77117.160000</td>\n",
       "      <td>1.278655</td>\n",
       "      <td>154.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.796076</td>\n",
       "      <td>5.131824</td>\n",
       "      <td>8.469040</td>\n",
       "      <td>8.168441</td>\n",
       "      <td>6.226139</td>\n",
       "      <td>7.792487</td>\n",
       "      <td>6.816335</td>\n",
       "      <td>8.795342</td>\n",
       "      <td>45.139920</td>\n",
       "      <td>74.494323</td>\n",
       "      <td>...</td>\n",
       "      <td>69.178850</td>\n",
       "      <td>48.517110</td>\n",
       "      <td>42.439452</td>\n",
       "      <td>54.761021</td>\n",
       "      <td>53.116208</td>\n",
       "      <td>68.537590</td>\n",
       "      <td>59.951999</td>\n",
       "      <td>51216.000000</td>\n",
       "      <td>5.212006</td>\n",
       "      <td>125.0071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.590219</td>\n",
       "      <td>9.233072</td>\n",
       "      <td>6.352605</td>\n",
       "      <td>8.429602</td>\n",
       "      <td>5.672564</td>\n",
       "      <td>5.705322</td>\n",
       "      <td>5.717624</td>\n",
       "      <td>3.420081</td>\n",
       "      <td>51.614896</td>\n",
       "      <td>35.512459</td>\n",
       "      <td>...</td>\n",
       "      <td>53.549937</td>\n",
       "      <td>32.363803</td>\n",
       "      <td>32.433584</td>\n",
       "      <td>19.400628</td>\n",
       "      <td>32.620884</td>\n",
       "      <td>19.512664</td>\n",
       "      <td>19.554736</td>\n",
       "      <td>0.004691</td>\n",
       "      <td>-2.489141</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.916229</td>\n",
       "      <td>4.216994</td>\n",
       "      <td>4.711545</td>\n",
       "      <td>6.462613</td>\n",
       "      <td>4.887217</td>\n",
       "      <td>2.638681</td>\n",
       "      <td>9.605809</td>\n",
       "      <td>5.234709</td>\n",
       "      <td>12.297724</td>\n",
       "      <td>13.739946</td>\n",
       "      <td>...</td>\n",
       "      <td>30.448892</td>\n",
       "      <td>12.895807</td>\n",
       "      <td>46.945675</td>\n",
       "      <td>25.583158</td>\n",
       "      <td>25.346667</td>\n",
       "      <td>13.812727</td>\n",
       "      <td>50.283615</td>\n",
       "      <td>0.004818</td>\n",
       "      <td>-4.231226</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2.608430</td>\n",
       "      <td>3.346465</td>\n",
       "      <td>5.201403</td>\n",
       "      <td>9.166944</td>\n",
       "      <td>6.192108</td>\n",
       "      <td>3.850187</td>\n",
       "      <td>7.960717</td>\n",
       "      <td>8.586406</td>\n",
       "      <td>8.729021</td>\n",
       "      <td>13.567499</td>\n",
       "      <td>...</td>\n",
       "      <td>47.680974</td>\n",
       "      <td>23.840776</td>\n",
       "      <td>49.293623</td>\n",
       "      <td>53.167952</td>\n",
       "      <td>30.650253</td>\n",
       "      <td>33.059270</td>\n",
       "      <td>68.353950</td>\n",
       "      <td>70830.750000</td>\n",
       "      <td>1.673402</td>\n",
       "      <td>149.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>7.801407</td>\n",
       "      <td>2.628427</td>\n",
       "      <td>5.543288</td>\n",
       "      <td>9.133362</td>\n",
       "      <td>7.014197</td>\n",
       "      <td>5.730589</td>\n",
       "      <td>4.246228</td>\n",
       "      <td>6.930445</td>\n",
       "      <td>20.505433</td>\n",
       "      <td>43.245446</td>\n",
       "      <td>...</td>\n",
       "      <td>50.628851</td>\n",
       "      <td>40.195478</td>\n",
       "      <td>29.783881</td>\n",
       "      <td>48.611503</td>\n",
       "      <td>24.333390</td>\n",
       "      <td>39.715531</td>\n",
       "      <td>29.428252</td>\n",
       "      <td>72485.310000</td>\n",
       "      <td>1.614970</td>\n",
       "      <td>150.9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>7.364198</td>\n",
       "      <td>8.455093</td>\n",
       "      <td>4.617628</td>\n",
       "      <td>3.805883</td>\n",
       "      <td>4.280772</td>\n",
       "      <td>6.398586</td>\n",
       "      <td>8.552977</td>\n",
       "      <td>8.138172</td>\n",
       "      <td>62.264979</td>\n",
       "      <td>34.005123</td>\n",
       "      <td>...</td>\n",
       "      <td>17.574150</td>\n",
       "      <td>27.390888</td>\n",
       "      <td>36.613344</td>\n",
       "      <td>34.837657</td>\n",
       "      <td>54.726959</td>\n",
       "      <td>52.072793</td>\n",
       "      <td>69.605594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.734951</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>7.094305</td>\n",
       "      <td>2.423077</td>\n",
       "      <td>2.934079</td>\n",
       "      <td>6.637124</td>\n",
       "      <td>4.526698</td>\n",
       "      <td>3.664447</td>\n",
       "      <td>4.901074</td>\n",
       "      <td>5.327160</td>\n",
       "      <td>17.190049</td>\n",
       "      <td>20.815255</td>\n",
       "      <td>...</td>\n",
       "      <td>19.473850</td>\n",
       "      <td>16.587847</td>\n",
       "      <td>22.185683</td>\n",
       "      <td>24.114444</td>\n",
       "      <td>17.959727</td>\n",
       "      <td>19.521095</td>\n",
       "      <td>26.108803</td>\n",
       "      <td>73446.170000</td>\n",
       "      <td>0.853824</td>\n",
       "      <td>150.9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>3.451784</td>\n",
       "      <td>3.164933</td>\n",
       "      <td>3.213005</td>\n",
       "      <td>9.450705</td>\n",
       "      <td>8.759146</td>\n",
       "      <td>8.331735</td>\n",
       "      <td>2.206001</td>\n",
       "      <td>6.427374</td>\n",
       "      <td>10.924665</td>\n",
       "      <td>11.090597</td>\n",
       "      <td>...</td>\n",
       "      <td>30.365158</td>\n",
       "      <td>72.978885</td>\n",
       "      <td>19.322682</td>\n",
       "      <td>56.298306</td>\n",
       "      <td>18.379814</td>\n",
       "      <td>53.551178</td>\n",
       "      <td>14.178791</td>\n",
       "      <td>55933.920000</td>\n",
       "      <td>2.408665</td>\n",
       "      <td>131.0084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Schord     Sspan    Ssweep      Stip    Bchord     Bspan    Bsweep  \\\n",
       "0    9.465233  9.191411  6.313146  6.181568  4.253219  3.362766  2.004250   \n",
       "1    5.050903  2.807665  7.250966  4.202998  7.871765  6.329711  3.563606   \n",
       "2    8.796076  5.131824  8.469040  8.168441  6.226139  7.792487  6.816335   \n",
       "3    5.590219  9.233072  6.352605  8.429602  5.672564  5.705322  5.717624   \n",
       "4    2.916229  4.216994  4.711545  6.462613  4.887217  2.638681  9.605809   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "395  2.608430  3.346465  5.201403  9.166944  6.192108  3.850187  7.960717   \n",
       "396  7.801407  2.628427  5.543288  9.133362  7.014197  5.730589  4.246228   \n",
       "397  7.364198  8.455093  4.617628  3.805883  4.280772  6.398586  8.552977   \n",
       "398  7.094305  2.423077  2.934079  6.637124  4.526698  3.664447  4.901074   \n",
       "399  3.451784  3.164933  3.213005  9.450705  8.759146  8.331735  2.206001   \n",
       "\n",
       "         Btip  Schordspan  Schordsweep  ...  SSweeptip  Bchordspan  \\\n",
       "0    3.767645   86.998844    59.755399  ...  39.025144   14.302581   \n",
       "1    6.148326   14.181241    36.623926  ...  30.475799   49.826002   \n",
       "2    8.795342   45.139920    74.494323  ...  69.178850   48.517110   \n",
       "3    3.420081   51.614896    35.512459  ...  53.549937   32.363803   \n",
       "4    5.234709   12.297724    13.739946  ...  30.448892   12.895807   \n",
       "..        ...         ...          ...  ...        ...         ...   \n",
       "395  8.586406    8.729021    13.567499  ...  47.680974   23.840776   \n",
       "396  6.930445   20.505433    43.245446  ...  50.628851   40.195478   \n",
       "397  8.138172   62.264979    34.005123  ...  17.574150   27.390888   \n",
       "398  5.327160   17.190049    20.815255  ...  19.473850   16.587847   \n",
       "399  6.427374   10.924665    11.090597  ...  30.365158   72.978885   \n",
       "\n",
       "     Bchordsweep  Bchordtip  Bspansweep   BSpantip  BSweeptip      Altitude  \\\n",
       "0       8.524515  16.024619    6.739826  12.669711   7.551304      0.004903   \n",
       "1      28.051867  48.398181   22.556595  38.917130  21.910210  77117.160000   \n",
       "2      42.439452  54.761021   53.116208  68.537590  59.951999  51216.000000   \n",
       "3      32.433584  19.400628   32.620884  19.512664  19.554736      0.004691   \n",
       "4      46.945675  25.583158   25.346667  13.812727  50.283615      0.004818   \n",
       "..           ...        ...         ...        ...        ...           ...   \n",
       "395    49.293623  53.167952   30.650253  33.059270  68.353950  70830.750000   \n",
       "396    29.783881  48.611503   24.333390  39.715531  29.428252  72485.310000   \n",
       "397    36.613344  34.837657   54.726959  52.072793  69.605594      0.000000   \n",
       "398    22.185683  24.114444   17.959727  19.521095  26.108803  73446.170000   \n",
       "399    19.322682  56.298306   18.379814  53.551178  14.178791  55933.920000   \n",
       "\n",
       "     Stability      Time  \n",
       "0    -5.121752    0.0100  \n",
       "1     1.278655  154.9973  \n",
       "2     5.212006  125.0071  \n",
       "3    -2.489141    0.0100  \n",
       "4    -4.231226    0.0100  \n",
       "..         ...       ...  \n",
       "395   1.673402  149.0006  \n",
       "396   1.614970  150.9995  \n",
       "397  -1.734951    0.0000  \n",
       "398   0.853824  150.9995  \n",
       "399   2.408665  131.0084  \n",
       "\n",
       "[400 rows x 23 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={0: \"Schord\", 1: \"Sspan\", 2: \"Ssweep\", 3: \"Stip\", 4: \"Bchord\", \n",
    "                        5: \"Bspan\", 6: \"Bsweep\", 7: \"Btip\", 8: \"Altitude\", 9: \"Stability\", 10: \"Time\"})\n",
    "df['Schordspan'] = df['Schord'] * df['Sspan']\n",
    "df['Schordsweep'] = df['Schord'] * df['Ssweep']\n",
    "df['Schordtip'] = df['Schord'] * df['Stip']\n",
    "df['Sspansweep'] = df['Sspan'] * df['Ssweep']\n",
    "df['SSpantip'] = df['Sspan'] * df['Stip']\n",
    "df['SSweeptip'] = df['Ssweep'] * df['Stip']\n",
    "\n",
    "df['Bchordspan'] = df['Bchord'] * df['Bspan']\n",
    "df['Bchordsweep'] = df['Bchord'] * df['Bsweep']\n",
    "df['Bchordtip'] = df['Bchord'] * df['Btip']\n",
    "df['Bspansweep'] = df['Bspan'] * df['Bsweep']\n",
    "df['BSpantip'] = df['Bspan'] * df['Btip']\n",
    "df['BSweeptip'] = df['Bsweep'] * df['Btip']\n",
    "alt = df.pop(\"Altitude\")\n",
    "stab = df.pop(\"Stability\")\n",
    "time = df.pop(\"Time\")\n",
    "\n",
    "df.insert(len(df.columns), \"Altitude\", alt)\n",
    "df.insert(len(df.columns), \"Stability\", stab)\n",
    "df.insert(len(df.columns), \"Time\", time)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2f07700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Schord</th>\n",
       "      <th>Sspan</th>\n",
       "      <th>Ssweep</th>\n",
       "      <th>Stip</th>\n",
       "      <th>Bchord</th>\n",
       "      <th>Bspan</th>\n",
       "      <th>Bsweep</th>\n",
       "      <th>Btip</th>\n",
       "      <th>Schordspan</th>\n",
       "      <th>Schordsweep</th>\n",
       "      <th>...</th>\n",
       "      <th>SSweeptip</th>\n",
       "      <th>Bchordspan</th>\n",
       "      <th>Bchordsweep</th>\n",
       "      <th>Bchordtip</th>\n",
       "      <th>Bspansweep</th>\n",
       "      <th>BSpantip</th>\n",
       "      <th>BSweeptip</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Stability</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.050903</td>\n",
       "      <td>2.807665</td>\n",
       "      <td>7.250966</td>\n",
       "      <td>4.202998</td>\n",
       "      <td>7.871765</td>\n",
       "      <td>6.329711</td>\n",
       "      <td>3.563606</td>\n",
       "      <td>6.148326</td>\n",
       "      <td>14.181241</td>\n",
       "      <td>36.623926</td>\n",
       "      <td>...</td>\n",
       "      <td>30.475799</td>\n",
       "      <td>49.826002</td>\n",
       "      <td>28.051867</td>\n",
       "      <td>48.398181</td>\n",
       "      <td>22.556595</td>\n",
       "      <td>38.917130</td>\n",
       "      <td>21.910210</td>\n",
       "      <td>77117.16</td>\n",
       "      <td>1.278655</td>\n",
       "      <td>154.9973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.796076</td>\n",
       "      <td>5.131824</td>\n",
       "      <td>8.469040</td>\n",
       "      <td>8.168441</td>\n",
       "      <td>6.226139</td>\n",
       "      <td>7.792487</td>\n",
       "      <td>6.816335</td>\n",
       "      <td>8.795342</td>\n",
       "      <td>45.139920</td>\n",
       "      <td>74.494323</td>\n",
       "      <td>...</td>\n",
       "      <td>69.178850</td>\n",
       "      <td>48.517110</td>\n",
       "      <td>42.439452</td>\n",
       "      <td>54.761021</td>\n",
       "      <td>53.116208</td>\n",
       "      <td>68.537590</td>\n",
       "      <td>59.951999</td>\n",
       "      <td>51216.00</td>\n",
       "      <td>5.212006</td>\n",
       "      <td>125.0071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.562160</td>\n",
       "      <td>4.337768</td>\n",
       "      <td>7.930397</td>\n",
       "      <td>4.372560</td>\n",
       "      <td>9.417980</td>\n",
       "      <td>8.246008</td>\n",
       "      <td>2.728282</td>\n",
       "      <td>6.326085</td>\n",
       "      <td>37.140668</td>\n",
       "      <td>67.901332</td>\n",
       "      <td>...</td>\n",
       "      <td>34.676133</td>\n",
       "      <td>77.660732</td>\n",
       "      <td>25.694900</td>\n",
       "      <td>59.578937</td>\n",
       "      <td>22.497430</td>\n",
       "      <td>52.164942</td>\n",
       "      <td>17.259340</td>\n",
       "      <td>54082.50</td>\n",
       "      <td>4.485508</td>\n",
       "      <td>129.0079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.703811</td>\n",
       "      <td>2.188438</td>\n",
       "      <td>9.143090</td>\n",
       "      <td>2.635864</td>\n",
       "      <td>9.087634</td>\n",
       "      <td>8.094306</td>\n",
       "      <td>6.826608</td>\n",
       "      <td>3.754130</td>\n",
       "      <td>19.047753</td>\n",
       "      <td>79.579730</td>\n",
       "      <td>...</td>\n",
       "      <td>24.099946</td>\n",
       "      <td>73.558093</td>\n",
       "      <td>62.037714</td>\n",
       "      <td>34.116158</td>\n",
       "      <td>55.256655</td>\n",
       "      <td>30.387077</td>\n",
       "      <td>25.627973</td>\n",
       "      <td>78784.51</td>\n",
       "      <td>0.613785</td>\n",
       "      <td>156.9962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.074672</td>\n",
       "      <td>3.479253</td>\n",
       "      <td>5.061755</td>\n",
       "      <td>2.201202</td>\n",
       "      <td>8.430403</td>\n",
       "      <td>6.003352</td>\n",
       "      <td>2.080965</td>\n",
       "      <td>3.394916</td>\n",
       "      <td>28.093824</td>\n",
       "      <td>40.872014</td>\n",
       "      <td>...</td>\n",
       "      <td>11.141944</td>\n",
       "      <td>50.610675</td>\n",
       "      <td>17.543371</td>\n",
       "      <td>28.620512</td>\n",
       "      <td>12.492762</td>\n",
       "      <td>20.380874</td>\n",
       "      <td>7.064700</td>\n",
       "      <td>59576.45</td>\n",
       "      <td>2.920013</td>\n",
       "      <td>136.0078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>5.247843</td>\n",
       "      <td>7.799644</td>\n",
       "      <td>8.441005</td>\n",
       "      <td>9.658211</td>\n",
       "      <td>6.937770</td>\n",
       "      <td>7.882306</td>\n",
       "      <td>6.353957</td>\n",
       "      <td>9.196173</td>\n",
       "      <td>40.931306</td>\n",
       "      <td>44.297067</td>\n",
       "      <td>...</td>\n",
       "      <td>81.524999</td>\n",
       "      <td>54.685626</td>\n",
       "      <td>44.082290</td>\n",
       "      <td>63.800932</td>\n",
       "      <td>50.083829</td>\n",
       "      <td>72.487046</td>\n",
       "      <td>58.432082</td>\n",
       "      <td>39893.78</td>\n",
       "      <td>5.851534</td>\n",
       "      <td>111.0041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2.608430</td>\n",
       "      <td>3.346465</td>\n",
       "      <td>5.201403</td>\n",
       "      <td>9.166944</td>\n",
       "      <td>6.192108</td>\n",
       "      <td>3.850187</td>\n",
       "      <td>7.960717</td>\n",
       "      <td>8.586406</td>\n",
       "      <td>8.729021</td>\n",
       "      <td>13.567499</td>\n",
       "      <td>...</td>\n",
       "      <td>47.680974</td>\n",
       "      <td>23.840776</td>\n",
       "      <td>49.293623</td>\n",
       "      <td>53.167952</td>\n",
       "      <td>30.650253</td>\n",
       "      <td>33.059270</td>\n",
       "      <td>68.353950</td>\n",
       "      <td>70830.75</td>\n",
       "      <td>1.673402</td>\n",
       "      <td>149.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>7.801407</td>\n",
       "      <td>2.628427</td>\n",
       "      <td>5.543288</td>\n",
       "      <td>9.133362</td>\n",
       "      <td>7.014197</td>\n",
       "      <td>5.730589</td>\n",
       "      <td>4.246228</td>\n",
       "      <td>6.930445</td>\n",
       "      <td>20.505433</td>\n",
       "      <td>43.245446</td>\n",
       "      <td>...</td>\n",
       "      <td>50.628851</td>\n",
       "      <td>40.195478</td>\n",
       "      <td>29.783881</td>\n",
       "      <td>48.611503</td>\n",
       "      <td>24.333390</td>\n",
       "      <td>39.715531</td>\n",
       "      <td>29.428252</td>\n",
       "      <td>72485.31</td>\n",
       "      <td>1.614970</td>\n",
       "      <td>150.9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>7.094305</td>\n",
       "      <td>2.423077</td>\n",
       "      <td>2.934079</td>\n",
       "      <td>6.637124</td>\n",
       "      <td>4.526698</td>\n",
       "      <td>3.664447</td>\n",
       "      <td>4.901074</td>\n",
       "      <td>5.327160</td>\n",
       "      <td>17.190049</td>\n",
       "      <td>20.815255</td>\n",
       "      <td>...</td>\n",
       "      <td>19.473850</td>\n",
       "      <td>16.587847</td>\n",
       "      <td>22.185683</td>\n",
       "      <td>24.114444</td>\n",
       "      <td>17.959727</td>\n",
       "      <td>19.521095</td>\n",
       "      <td>26.108803</td>\n",
       "      <td>73446.17</td>\n",
       "      <td>0.853824</td>\n",
       "      <td>150.9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>3.451784</td>\n",
       "      <td>3.164933</td>\n",
       "      <td>3.213005</td>\n",
       "      <td>9.450705</td>\n",
       "      <td>8.759146</td>\n",
       "      <td>8.331735</td>\n",
       "      <td>2.206001</td>\n",
       "      <td>6.427374</td>\n",
       "      <td>10.924665</td>\n",
       "      <td>11.090597</td>\n",
       "      <td>...</td>\n",
       "      <td>30.365158</td>\n",
       "      <td>72.978885</td>\n",
       "      <td>19.322682</td>\n",
       "      <td>56.298306</td>\n",
       "      <td>18.379814</td>\n",
       "      <td>53.551178</td>\n",
       "      <td>14.178791</td>\n",
       "      <td>55933.92</td>\n",
       "      <td>2.408665</td>\n",
       "      <td>131.0084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Schord     Sspan    Ssweep      Stip    Bchord     Bspan    Bsweep  \\\n",
       "1    5.050903  2.807665  7.250966  4.202998  7.871765  6.329711  3.563606   \n",
       "2    8.796076  5.131824  8.469040  8.168441  6.226139  7.792487  6.816335   \n",
       "5    8.562160  4.337768  7.930397  4.372560  9.417980  8.246008  2.728282   \n",
       "6    8.703811  2.188438  9.143090  2.635864  9.087634  8.094306  6.826608   \n",
       "8    8.074672  3.479253  5.061755  2.201202  8.430403  6.003352  2.080965   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "393  5.247843  7.799644  8.441005  9.658211  6.937770  7.882306  6.353957   \n",
       "395  2.608430  3.346465  5.201403  9.166944  6.192108  3.850187  7.960717   \n",
       "396  7.801407  2.628427  5.543288  9.133362  7.014197  5.730589  4.246228   \n",
       "398  7.094305  2.423077  2.934079  6.637124  4.526698  3.664447  4.901074   \n",
       "399  3.451784  3.164933  3.213005  9.450705  8.759146  8.331735  2.206001   \n",
       "\n",
       "         Btip  Schordspan  Schordsweep  ...  SSweeptip  Bchordspan  \\\n",
       "1    6.148326   14.181241    36.623926  ...  30.475799   49.826002   \n",
       "2    8.795342   45.139920    74.494323  ...  69.178850   48.517110   \n",
       "5    6.326085   37.140668    67.901332  ...  34.676133   77.660732   \n",
       "6    3.754130   19.047753    79.579730  ...  24.099946   73.558093   \n",
       "8    3.394916   28.093824    40.872014  ...  11.141944   50.610675   \n",
       "..        ...         ...          ...  ...        ...         ...   \n",
       "393  9.196173   40.931306    44.297067  ...  81.524999   54.685626   \n",
       "395  8.586406    8.729021    13.567499  ...  47.680974   23.840776   \n",
       "396  6.930445   20.505433    43.245446  ...  50.628851   40.195478   \n",
       "398  5.327160   17.190049    20.815255  ...  19.473850   16.587847   \n",
       "399  6.427374   10.924665    11.090597  ...  30.365158   72.978885   \n",
       "\n",
       "     Bchordsweep  Bchordtip  Bspansweep   BSpantip  BSweeptip  Altitude  \\\n",
       "1      28.051867  48.398181   22.556595  38.917130  21.910210  77117.16   \n",
       "2      42.439452  54.761021   53.116208  68.537590  59.951999  51216.00   \n",
       "5      25.694900  59.578937   22.497430  52.164942  17.259340  54082.50   \n",
       "6      62.037714  34.116158   55.256655  30.387077  25.627973  78784.51   \n",
       "8      17.543371  28.620512   12.492762  20.380874   7.064700  59576.45   \n",
       "..           ...        ...         ...        ...        ...       ...   \n",
       "393    44.082290  63.800932   50.083829  72.487046  58.432082  39893.78   \n",
       "395    49.293623  53.167952   30.650253  33.059270  68.353950  70830.75   \n",
       "396    29.783881  48.611503   24.333390  39.715531  29.428252  72485.31   \n",
       "398    22.185683  24.114444   17.959727  19.521095  26.108803  73446.17   \n",
       "399    19.322682  56.298306   18.379814  53.551178  14.178791  55933.92   \n",
       "\n",
       "     Stability      Time  \n",
       "1     1.278655  154.9973  \n",
       "2     5.212006  125.0071  \n",
       "5     4.485508  129.0079  \n",
       "6     0.613785  156.9962  \n",
       "8     2.920013  136.0078  \n",
       "..         ...       ...  \n",
       "393   5.851534  111.0041  \n",
       "395   1.673402  149.0006  \n",
       "396   1.614970  150.9995  \n",
       "398   0.853824  150.9995  \n",
       "399   2.408665  131.0084  \n",
       "\n",
       "[197 rows x 23 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = df[df['Time'] > 90]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d818a4",
   "metadata": {},
   "source": [
    "# NN Stability Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1563f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(45, 90)\n",
    "        self.activation1 = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(90, 60)\n",
    "        self.activation2 = torch.nn.ReLU()\n",
    "        self.linear3 = torch.nn.Linear(60, 30)\n",
    "        self.activation3 = torch.nn.ReLU()\n",
    "        self.linear4 = torch.nn.Linear(30, 10)\n",
    "        self.activation4 = torch.nn.ReLU()\n",
    "        self.linear5 = torch.nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.activation2(x)\n",
    "        x = self.linear3(x)\n",
    "        x = self.activation3(x)\n",
    "        x = self.linear4(x)\n",
    "        x = self.activation4(x)\n",
    "        x = self.linear5(x)\n",
    "        \n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff9703e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_arrays(data_arrays, batch_size, train = True):\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "756fc5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classif = Classifier()\n",
    "classif.double()\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "raw_X = df.iloc[:,:8]\n",
    "raw_Y = df.iloc[:,-1] > 90\n",
    "batch_size = 10\n",
    "idxs = np.array(list(range(0, 300)))# + list(range(0))) # FOR CV\n",
    "\n",
    "train_X = torch.from_numpy(poly.fit_transform(raw_X.iloc[idxs])).double()\n",
    "train_Y = torch.from_numpy(np.array([[x] for x in raw_Y.iloc[idxs]])).double()\n",
    "\n",
    "test_X = torch.from_numpy(poly.fit_transform(raw_X[300:400])).double()\n",
    "test_Y = torch.from_numpy(np.array([[x] for x in raw_Y[300:400]])).double()\n",
    "data_iter = load_arrays((train_X, train_Y), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "18b6a402",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()\n",
    "trainer = torch.optim.SGD(classif.parameters(), lr=0.01)\n",
    "num_epochs = 250\n",
    "def train(num_epochs, trainer, loss):\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        for X, y in data_iter:\n",
    "            X.requires_grad = True\n",
    "            l = loss(classif(X) ,y)\n",
    "\n",
    "            trainer.zero_grad() #sets gradients to zero\n",
    "\n",
    "            l.backward() # back propagation\n",
    "\n",
    "            trainer.step() # parameter update\n",
    "\n",
    "        l = loss(classif(train_X), train_Y)\n",
    "        if epoch % 50 == 0:\n",
    "            print(f'epoch {epoch + 1}, loss {l:f}')\n",
    "            #print(X.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "48b477d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.527873\n",
      "epoch 51, loss 0.034600\n",
      "epoch 101, loss 0.005178\n",
      "epoch 151, loss 0.001587\n",
      "epoch 201, loss 0.000876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, tensor([0.8800]))"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(num_epochs, trainer, loss), sum((classif(test_X) >= 0.5) == test_Y)/len(test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c65752f",
   "metadata": {},
   "source": [
    "# Altitude Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a3954000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 0.9929351496740758\n",
      "Test RMSE Quad 1815.417729777189\n",
      "Test RMSE ridge 2056.5256021326427\n",
      "Test RMSE lasso 1815.019990798251\n",
      "Train RMSE 1186.314188487517\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "raw = filtered_df.iloc[:,:8]\n",
    "qr = LinearRegression()\n",
    "idxs = np.array(list(range(150)))# + list(range(50)))\n",
    "\n",
    "ridge = Ridge(alpha=0.6)\n",
    "ridge.fit(poly.fit_transform(raw.iloc[idxs]), filtered_df.iloc[idxs, -3])\n",
    "lasso = Lasso(alpha=.2)\n",
    "lasso.fit(poly.fit_transform(raw.iloc[idxs]), filtered_df.iloc[idxs, -3])\n",
    "\n",
    "qr.fit(poly.fit_transform(raw.iloc[idxs]), filtered_df.iloc[idxs, -3])\n",
    "print('R2', ridge.score(poly.fit_transform(raw.iloc[idxs]), filtered_df.iloc[idxs, -3]))\n",
    "print('Test RMSE Quad', np.sqrt(MSE(filtered_df.iloc[150:, -3], qr.predict(poly.fit_transform(raw[150:])))))\n",
    "print('Test RMSE ridge', np.sqrt(MSE(filtered_df.iloc[150:, -3], ridge.predict(poly.fit_transform(raw[150:])))))\n",
    "print('Test RMSE lasso', np.sqrt(MSE(filtered_df.iloc[150:, -3], lasso.predict(poly.fit_transform(raw[150:])))))\n",
    "\n",
    "print('Train RMSE', np.sqrt(MSE(filtered_df.iloc[idxs, -3], ridge.predict(poly.fit_transform(raw.iloc[idxs])))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c5748c",
   "metadata": {},
   "source": [
    "# Solving COP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3aeef2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (linear1): Linear(in_features=45, out_features=90, bias=True)\n",
       "  (activation1): ReLU()\n",
       "  (linear2): Linear(in_features=90, out_features=60, bias=True)\n",
       "  (activation2): ReLU()\n",
       "  (linear3): Linear(in_features=60, out_features=30, bias=True)\n",
       "  (activation3): ReLU()\n",
       "  (linear4): Linear(in_features=30, out_features=10, bias=True)\n",
       "  (activation4): ReLU()\n",
       "  (linear5): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stab_constraint(X):\n",
    "    with torch.no_grad():\n",
    "        return classif(torch.from_numpy(poly.fit_transform([X])))[0] - 0.6\n",
    "def l0(X):\n",
    "    return X[0]-2\n",
    "def l1(X):\n",
    "    return X[1]-2\n",
    "def l2(X):\n",
    "    return X[2]-2\n",
    "def l3(X):\n",
    "    return X[3]-2\n",
    "def l4(X):\n",
    "    return X[4]-2\n",
    "def l5(X):\n",
    "    return X[5]-2\n",
    "def l6(X):\n",
    "    return X[6]-2\n",
    "def l7(X):\n",
    "    return X[7]-2\n",
    "\n",
    "def u0(X):\n",
    "    return 10-X[0]\n",
    "def u1(X):\n",
    "    return 10-X[1]\n",
    "def u2(X):\n",
    "    return 10-X[2]\n",
    "def u3(X):\n",
    "    return 10-X[3]\n",
    "def u4(X):\n",
    "    return 10-X[4]\n",
    "def u5(X):\n",
    "    return 10-X[5]\n",
    "def u6(X):\n",
    "    return 10-X[6]\n",
    "def u7(X):\n",
    "    return 10-X[7]\n",
    "def objective(X):\n",
    "    return -ridge.predict(poly.fit_transform([X]))[0]\n",
    "classif.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a84dce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ineq_cons = {'type': 'ineq',\n",
    "             'fun' : stab_constraint}\n",
    "L0 = {'type': 'ineq',\n",
    "             'fun' : l0}\n",
    "L1 = {'type': 'ineq',\n",
    "             'fun' : l1}\n",
    "L2 = {'type': 'ineq',\n",
    "             'fun' : l2}\n",
    "L3 = {'type': 'ineq',\n",
    "             'fun' : l3}\n",
    "L4 = {'type': 'ineq',\n",
    "             'fun' : l4}\n",
    "L5 = {'type': 'ineq',\n",
    "             'fun' : l5}\n",
    "L6 = {'type': 'ineq',\n",
    "             'fun' : l6}\n",
    "L7 = {'type': 'ineq',\n",
    "             'fun' : l7}\n",
    "U0 = {'type': 'ineq',\n",
    "             'fun' : u0}\n",
    "U1 = {'type': 'ineq',\n",
    "             'fun' : u1}\n",
    "U2 = {'type': 'ineq',\n",
    "             'fun' : u2}\n",
    "U3 = {'type': 'ineq',\n",
    "             'fun' : u3}\n",
    "U4 = {'type': 'ineq',\n",
    "             'fun' : u4}\n",
    "U5 = {'type': 'ineq',\n",
    "             'fun' : u5}\n",
    "U6 = {'type': 'ineq',\n",
    "             'fun' : u6}\n",
    "U7 = {'type': 'ineq',\n",
    "             'fun' : u7}\n",
    "# x = minimize(objective, X0, method='trust-constr', options = {'disp':True}).x#, constraints = [ineq_cons], options={'ftol': 1e-9, 'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1043e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "samples = filtered_df.iloc[np.random.choice(len(filtered_df), 197), :8]\n",
    "results = []\n",
    "for i in range(len(samples)):\n",
    "    X0 = np.array(samples.iloc[i])\n",
    "    res = minimize(objective, X0, method='COBYLA', \n",
    "               constraints = [ineq_cons, L0, L1, L2, L3, L4, L5, L6, L7, U0, U1, U2, U3, U4, U5, U6, U7], \n",
    "               options = {'verbose':1, 'display':1, 'maxiter':10}) # constraints = [constraint], options = {'verbose':1})#, bounds = bounds)\n",
    "    results.append((X0, res.x, -res.fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e76fd65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([8.76254164, 2.40324077, 8.77518014, 3.82322874, 4.85104019,\n",
       "         4.60577037, 8.11653639, 8.55373399]),\n",
       "  array([ 8.37781964,  2.        , 10.        ,  3.78840952,  4.72647194,\n",
       "          3.82683827,  9.23497365,  8.51699631]),\n",
       "  99990.03446809443),\n",
       " (array([8.76254164, 2.40324077, 8.77518014, 3.82322874, 4.85104019,\n",
       "         4.60577037, 8.11653639, 8.55373399]),\n",
       "  array([ 8.37781964,  2.        , 10.        ,  3.78840952,  4.72647194,\n",
       "          3.82683827,  9.23497365,  8.51699631]),\n",
       "  99990.03446809443),\n",
       " (array([3.02924659, 2.74524202, 6.29978985, 7.17708261, 5.44099747,\n",
       "         3.88833632, 4.58883198, 2.70679481]),\n",
       "  array([2.87590522, 2.        , 7.79436646, 7.1287923 , 5.34349866,\n",
       "         3.48989421, 5.66564727, 3.70702818]),\n",
       "  99108.85424540826),\n",
       " (array([3.02924659, 2.74524202, 6.29978985, 7.17708261, 5.44099747,\n",
       "         3.88833632, 4.58883198, 2.70679481]),\n",
       "  array([2.87590522, 2.        , 7.79436646, 7.1287923 , 5.34349866,\n",
       "         3.48989421, 5.66564727, 3.70702818]),\n",
       "  99108.85424540826),\n",
       " (array([2.32452262, 2.58871554, 9.32749721, 9.99315489, 4.52452962,\n",
       "         7.02169385, 4.2840132 , 2.97129558]),\n",
       "  array([ 2.04301842,  2.        , 10.        ,  9.85306499,  4.3865873 ,\n",
       "          6.39945625,  5.48669919,  2.97060992]),\n",
       "  97665.0784455041),\n",
       " (array([5.21541801, 3.2452491 , 8.89373312, 5.15294394, 7.57586859,\n",
       "         4.11137217, 7.01092286, 2.74712375]),\n",
       "  array([ 5.12875602,  2.27630273, 10.        ,  5.13481971,  7.51955764,\n",
       "          3.91592027,  8.03480318,  3.75542176]),\n",
       "  97529.87612909876),\n",
       " (array([5.21541801, 3.2452491 , 8.89373312, 5.15294394, 7.57586859,\n",
       "         4.11137217, 7.01092286, 2.74712375]),\n",
       "  array([ 5.12875602,  2.27630273, 10.        ,  5.13481971,  7.51955764,\n",
       "          3.91592027,  8.03480318,  3.75542176]),\n",
       "  97529.87612909876),\n",
       " (array([5.21541801, 3.2452491 , 8.89373312, 5.15294394, 7.57586859,\n",
       "         4.11137217, 7.01092286, 2.74712375]),\n",
       "  array([ 5.12875602,  2.27630273, 10.        ,  5.13481971,  7.51955764,\n",
       "          3.91592027,  8.03480318,  3.75542176]),\n",
       "  97529.87612909876),\n",
       " (array([2.18813213, 2.9292535 , 9.03466641, 7.78791587, 3.77742236,\n",
       "         6.61714789, 2.36987329, 4.4287817 ]),\n",
       "  array([ 2.05427848,  2.        , 10.        ,  7.73519326,  3.72286974,\n",
       "          6.30075043,  3.47672048,  4.41929283]),\n",
       "  97505.21690388097),\n",
       " (array([4.33129396, 3.20238894, 9.66627147, 3.24857185, 8.74241455,\n",
       "         5.19331968, 9.87308596, 9.479611  ]),\n",
       "  array([4.24805152, 2.23641309, 9.8471118 , 3.23839523, 8.71013078,\n",
       "         5.03202919, 9.88293463, 9.48044913]),\n",
       "  96680.2825257944)]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(results, key = lambda x: x[2], reverse = True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b87204",
   "metadata": {},
   "source": [
    "# Alternative Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bbdd33b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinateAscentQuad(stab_classifier, alt_predictor, initial = [0,0,0,0,0,0,0,0], inc = 0.0000001, max_iter = 10000, confidence = 0.95):\n",
    "    '''\n",
    "    Keep increasing in direction until unstable. \n",
    "    '''\n",
    "    M = {}\n",
    "    c = 9\n",
    "    for i in range(8):\n",
    "        for j in range(i, 8):\n",
    "            M[(i,j)] = c\n",
    "            c += 1\n",
    "    def partials(x):\n",
    "        grad = []\n",
    "        coef = alt_predictor.coef_\n",
    "        for i in range(8):\n",
    "            g = coef[1 + i]\n",
    "            for j in range(8):\n",
    "                if i == j:\n",
    "                    g += 2*x[i]*coef[M[i,i]]\n",
    "                else:\n",
    "                    g += coef[M[min([i,j]), max([i,j])]]*x[j]\n",
    "            grad.append(g)\n",
    "        return np.array(grad)\n",
    "    \n",
    "    x = initial\n",
    "    old = qr.predict(poly.fit_transform([x]))\n",
    "    for _ in range(max_iter):\n",
    "        #for i in range(8):\n",
    "        y = np.array(x)\n",
    "        # y[i] += np.sign(alt_predictor.coef_[i])*inc\n",
    "        # print(y, partials(x)*inc)\n",
    "        y += partials(x) * inc\n",
    "        if np.all(y > 2.5) and qr.predict(poly.fit_transform([y])) > old:\n",
    "            nxt = stab_classifier(torch.from_numpy(poly.fit_transform([y])))[0]\n",
    "            if nxt > confidence or np.random.rand() > 0.5:\n",
    "                if nxt <= confidence:\n",
    "                    print('Non greedy step')\n",
    "                x = y[:]\n",
    "                #print(qr.predict(poly.fit_transform([y])) - old)\n",
    "                old = qr.predict(poly.fit_transform([y]))\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        print('No more feasible directions at iteration', _, '.', qr.predict(poly.fit_transform([x])) - qr.predict(poly.fit_transform([initial])))\n",
    "        break\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a5f23cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more feasible directions at iteration 5845 . [39176.75]\n",
      "[4.82380255 6.74118993 8.26776052 5.40919866 6.95306475 9.69790705\n",
      " 2.83948251 5.78381106] [42007.3568367] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[78925.36037793] [4.4090305  2.50080525 9.10555224 5.29160709 6.82691421 9.02145405\n",
      " 3.21750298 5.75721313] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[8.93118239 8.0127891  9.97709212 8.00819807 2.91740485 9.66763027\n",
      " 4.27111457 6.41234245] [38083.98579968] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[38083.98579968] [8.93118239 8.0127891  9.97709212 8.00819807 2.91740485 9.66763027\n",
      " 4.27111457 6.41234245] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.08143832 5.49587179 6.29274552 9.61414548 9.6211931  5.716947\n",
      " 7.03471605 4.12567358] [49443.8653848] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[49443.8653848] [2.08143832 5.49587179 6.29274552 9.61414548 9.6211931  5.716947\n",
      " 7.03471605 4.12567358] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 5845 . [39176.75]\n",
      "[4.82380255 6.74118993 8.26776052 5.40919866 6.95306475 9.69790705\n",
      " 2.83948251 5.78381106] [42007.3568367] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[78925.36037793] [4.4090305  2.50080525 9.10555224 5.29160709 6.82691421 9.02145405\n",
      " 3.21750298 5.75721313] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[3.42529972 3.12091281 6.22450424 3.86772238 2.05499433 5.28858019\n",
      " 7.22884385 3.77197677] [77040.73649469] tensor([[0.9990]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[77040.73649469] [3.42529972 3.12091281 6.22450424 3.86772238 2.05499433 5.28858019\n",
      " 7.22884385 3.77197677] tensor([[0.9990]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 2382 . [31779.75]\n",
      "[3.15625135 5.03102599 4.70969599 3.06083945 9.29774736 4.79142794\n",
      " 8.05243392 4.79614511] [50944.89244003] tensor([[0.9979]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[81346.81495921] [2.99185225 2.500838   5.44728979 3.06624515 9.18228938 4.43359063\n",
      " 8.06538962 4.81102135] tensor([[0.8945]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.42158645 5.36692403 4.19314939 9.88923386 3.3281671  7.72567782\n",
      " 2.5713273  4.58021405] [43921.2861092] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[43921.2861092] [2.42158645 5.36692403 4.19314939 9.88923386 3.3281671  7.72567782\n",
      " 2.5713273  4.58021405] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 4074 . [36539.75]\n",
      "[3.03349873 5.98991279 7.60201447 2.65350567 6.81253481 9.09042745\n",
      " 2.53521989 7.94049156] [45875.90841786] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[80169.03990189] [2.72666018 2.50018198 8.38647033 2.63560126 6.75596192 8.53698218\n",
      " 2.80657449 7.90845974] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.24938549 7.1355691  9.60357587 6.03064032 9.55679646 9.94656893\n",
      " 5.29311738 3.4859656 ] [42781.92518807] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[42781.92518807] [2.24938549 7.1355691  9.60357587 6.03064032 9.55679646 9.94656893\n",
      " 5.29311738 3.4859656 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 108 . [1759.5]\n",
      "[7.80140724 2.62842748 5.54328779 9.13336153 7.01419669 5.73058897\n",
      " 4.2462284  6.93044481] [71446.04961701] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73105.28787059] [7.79091898 2.50056969 5.57366675 9.12978068 7.01033335 5.70911804\n",
      " 4.25315685 6.93010543] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[3.55884111 8.82054754 5.0221135  9.09558674 9.55597083 9.22706312\n",
      " 3.25523373 5.21691621] [34249.16780787] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[34249.16780787] [3.55884111 8.82054754 5.0221135  9.09558674 9.55597083 9.22706312\n",
      " 3.25523373 5.21691621] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.23961504 8.3725092  5.76464559 8.49609801 5.52093922 8.51519405\n",
      " 6.79952069 5.19043906] [35670.99391096] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[35670.99391096] [2.23961504 8.3725092  5.76464559 8.49609801 5.52093922 8.51519405\n",
      " 6.79952069 5.19043906] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[8.83000503 3.1276826  3.02323138 9.23555348 2.24817777 7.03314596\n",
      " 8.09570781 9.44711057] [57975.68378887] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[57975.68378887] [8.83000503 3.1276826  3.02323138 9.23555348 2.24817777 7.03314596\n",
      " 8.09570781 9.44711057] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1502 . [20181.75]\n",
      "[4.27708762 4.11694671 5.97936026 7.57877923 5.32415722 7.90499279\n",
      " 6.21599661 5.62194636] [58515.93787097] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[77518.29885058] [4.15647467 2.50040924 6.36240666 7.54028077 5.27854047 7.68299347\n",
      " 6.29358925 5.60844755] tensor([[0.9927]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[3.38506849 3.75294058 9.5478579  2.41258871 4.68348589 4.7158803\n",
      " 3.87426201 6.65679341] [76954.71047766] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[76954.71047766] [3.38506849 3.75294058 9.5478579  2.41258871 4.68348589 4.7158803\n",
      " 3.87426201 6.65679341] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[7.51240616 6.89222388 2.27433044 4.54304472 7.5555095  9.23104571\n",
      " 6.35526986 2.10700777] [32790.12947708] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[32790.12947708] [7.51240616 6.89222388 2.27433044 4.54304472 7.5555095  9.23104571\n",
      " 6.35526986 2.10700777] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1561 . [19296.25]\n",
      "[7.83616152 4.12446818 8.26146515 7.8197602  2.56544452 9.52279921\n",
      " 6.45425932 4.03578958] [59318.15330447] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[77461.87551889] [7.68660329 2.50053863 8.54160659 7.77540492 2.51828605 9.28683399\n",
      " 6.56177822 4.01286953] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.91825354 8.84363622 8.66625149 2.02358779 9.74090145 9.86560545\n",
      " 7.37689289 9.83481264] [37937.64892269] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[37937.64892269] [4.91825354 8.84363622 8.66625149 2.02358779 9.74090145 9.86560545\n",
      " 7.37689289 9.83481264] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[9.58208102 3.06765062 6.30107851 9.56138391 2.079334   9.88368351\n",
      " 7.93913278 4.99526955] [64139.50809944] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[64139.50809944] [9.58208102 3.06765062 6.30107851 9.56138391 2.079334   9.88368351\n",
      " 7.93913278 4.99526955] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.41785327 8.26680725 4.55367652 4.91451848 5.77937036 9.39042502\n",
      " 2.42309088 4.50039664] [34848.44729995] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[34848.44729995] [2.41785327 8.26680725 4.55367652 4.91451848 5.77937036 9.39042502\n",
      " 2.42309088 4.50039664] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[8.40079326 9.3841775  2.31882667 5.22013186 6.65516209 8.69986095\n",
      " 6.19268974 9.05128145] [31404.31568233] tensor([[0.9995]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[31404.31568233] [8.40079326 9.3841775  2.31882667 5.22013186 6.65516209 8.69986095\n",
      " 6.19268974 9.05128145] tensor([[0.9995]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[6.70066522 3.04066453 3.44555526 2.19836695 3.57994109 6.26423593\n",
      " 4.54553226 7.60479519] [62156.25871546] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[62156.25871546] [6.70066522 3.04066453 3.44555526 2.19836695 3.57994109 6.26423593\n",
      " 4.54553226 7.60479519] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.42431165 2.29500017 2.62214858 6.27300698 7.97761983 8.26637821\n",
      " 4.20514328 5.36314825] [65425.48498542] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[65425.48498542] [4.42431165 2.29500017 2.62214858 6.27300698 7.97761983 8.26637821\n",
      " 4.20514328 5.36314825] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[6.91978916 4.53707388 7.9328357  8.30605018 9.08887307 6.69618702\n",
      " 2.00585872 2.81610416] [54833.86356425] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[54833.86356425] [6.91978916 4.53707388 7.9328357  8.30605018 9.08887307 6.69618702\n",
      " 2.00585872 2.81610416] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.08143832 5.49587179 6.29274552 9.61414548 9.6211931  5.716947\n",
      " 7.03471605 4.12567358] [49443.8653848] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[49443.8653848] [2.08143832 5.49587179 6.29274552 9.61414548 9.6211931  5.716947\n",
      " 7.03471605 4.12567358] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more feasible directions at iteration 4197 . [40588.5]\n",
      "[4.20404871 6.23903807 9.53722911 4.87370122 5.62376644 8.01605349\n",
      " 3.50606934 3.87734483] [48474.36513678] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[86517.2008934] [ 3.85391216  2.50117071 10.18919504  4.7952754   5.47010527  7.30372936\n",
      "  3.7533133   3.86307765] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[5.52565651 7.8627154  7.70078007 3.22432224 9.65843035 8.85661078\n",
      " 3.97036025 9.9543257 ] [38241.89522611] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[38241.89522611] [5.52565651 7.8627154  7.70078007 3.22432224 9.65843035 8.85661078\n",
      " 3.97036025 9.9543257 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1793 . [25092.75]\n",
      "[7.55770164 4.50361243 8.21981413 9.34081355 7.3479328  6.0781645\n",
      " 8.63311071 5.71729505] [59185.27211982] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[83371.67919515] [7.39078563 2.50059955 8.59522579 9.2726016  7.26540399 5.76620497\n",
      " 8.68151246 5.71658802] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "Non greedy step\n",
      "[3.0885825  7.34552638 5.19000697 2.65042012 8.70100458 8.68577093\n",
      " 7.85250398 8.18927875] [36754.46835563] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[60558.93500346] [2.87622199 4.05391678 6.35500247 2.66367772 8.6274635  8.47539558\n",
      " 7.87078521 8.13509009] tensor([[0.5995]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.75209249 3.86500166 2.10559135 4.8232818  7.21272293 6.38729759\n",
      " 8.33755428 9.08530604] [51020.46621753] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[51020.46621753] [4.75209249 3.86500166 2.10559135 4.8232818  7.21272293 6.38729759\n",
      " 8.33755428 9.08530604] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[3.51324278 3.07721551 6.85920372 6.88783709 9.21928215 6.05656858\n",
      " 5.77688879 2.11950605] [73219.8737354] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73219.8737354] [3.51324278 3.07721551 6.85920372 6.88783709 9.21928215 6.05656858\n",
      " 5.77688879 2.11950605] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1 . [0.5]\n",
      "[3.13647961 8.48256887 3.92780283 8.36598977 3.9629386  9.09679814\n",
      " 8.10348771 4.7824802 ] [33025.59400564] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[33025.95353924] [3.13649289 8.48250358 3.92796837 8.36596527 3.9629314  9.09684036\n",
      " 8.10346432 4.78244658] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[8.44049955 2.1746643  5.92928775 4.05607782 8.02181382 7.98377955\n",
      " 9.71931208 2.91415316] [76711.30682215] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[76711.30682215] [8.44049955 2.1746643  5.92928775 4.05607782 8.02181382 7.98377955\n",
      " 9.71931208 2.91415316] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 5958 . [35062.25]\n",
      "[6.18697757 6.56882086 5.81054738 4.11732198 8.37180208 9.82121527\n",
      " 4.39598059 8.38180369] [39240.30250222] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73133.91439825] [5.81653399 2.50043775 6.9145374  4.07390172 8.31132818 9.38436951\n",
      " 4.6971382  8.34205251] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[3.45178366 3.16493323 3.21300463 9.45070468 8.7591459  8.33173528\n",
      " 2.20600069 6.42737392] [56321.8718417] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[56321.8718417] [3.45178366 3.16493323 3.21300463 9.45070468 8.7591459  8.33173528\n",
      " 2.20600069 6.42737392] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[6.26869478 2.7793247  2.85418812 9.87090656 8.23408446 4.93358931\n",
      " 2.15131749 8.82074611] [62247.78215649] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[62247.78215649] [6.26869478 2.7793247  2.85418812 9.87090656 8.23408446 4.93358931\n",
      " 2.15131749 8.82074611] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 318 . [5185.75]\n",
      "[6.06170208 2.87496314 6.90281982 2.70510471 7.12808567 6.70217093\n",
      " 3.84531715 3.59228077] [72725.73585299] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[77536.43766143] [6.02908693 2.50034578 6.9854691  2.70532951 7.11357809 6.63909737\n",
      " 3.86743006 3.59457598] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[5.47555738 4.89731791 5.30721761 2.42642505 5.30376549 8.10282177\n",
      " 9.92544991 8.50215086] [50072.33684163] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[50072.33684163] [5.47555738 4.89731791 5.30721761 2.42642505 5.30376549 8.10282177\n",
      " 9.92544991 8.50215086] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[9.58208102 3.06765062 6.30107851 9.56138391 2.079334   9.88368351\n",
      " 7.93913278 4.99526955] [64139.50809944] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[64139.50809944] [9.58208102 3.06765062 6.30107851 9.56138391 2.079334   9.88368351\n",
      " 7.93913278 4.99526955] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[5.26580953 4.97583277 9.0757182  7.6018415  2.07617314 9.49516943\n",
      " 9.77873692 3.43226772] [56978.07774736] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[56978.07774736] [5.26580953 4.97583277 9.0757182  7.6018415  2.07617314 9.49516943\n",
      " 9.77873692 3.43226772] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.27814356 8.96585095 7.57448175 8.7051576  4.56471608 8.7318882\n",
      " 8.79337048 7.01202137] [36172.93601571] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[36172.93601571] [4.27814356 8.96585095 7.57448175 8.7051576  4.56471608 8.7318882\n",
      " 8.79337048 7.01202137] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.12717718 4.24935594 4.83282894 9.48940368 6.69310519 4.95351523\n",
      " 4.76269905 3.49531252] [58366.38822245] tensor([[0.9992]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[58366.38822245] [2.12717718 4.24935594 4.83282894 9.48940368 6.69310519 4.95351523\n",
      " 4.76269905 3.49531252] tensor([[0.9992]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1378 . [18393.25]\n",
      "[9.25067508 3.96535082 6.35253056 7.82715472 7.14608988 4.61303537\n",
      " 3.0952779  3.68570653] [60116.86067493] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[77505.19115906] [9.11807496 2.50097351 6.6961807  7.79061097 7.07535637 4.31546944\n",
      " 3.17590308 3.69003864] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1964 . [24302.25]\n",
      "[7.15585233 4.56683534 8.60808435 9.35819159 7.10463724 8.48446358\n",
      " 7.18576991 8.61969735] [55936.90063536] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[79273.97608407] [6.97333329 2.50032633 8.95698646 9.2785242  7.05667578 8.19680057\n",
      " 7.28481466 8.60646599] tensor([[0.9881]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[8.07467226 3.47925257 5.06175521 2.20120157 8.43040333 6.00335154\n",
      " 2.08096464 3.39491605] [59236.75464846] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[59236.75464846] [8.07467226 3.47925257 5.06175521 2.20120157 8.43040333 6.00335154\n",
      " 2.08096464 3.39491605] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[3.57861903 6.280178   8.65911151 9.68024777 5.08156352 7.32347276\n",
      " 7.9498362  2.06146579] [48111.02279279] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[48111.02279279] [3.57861903 6.280178   8.65911151 9.68024777 5.08156352 7.32347276\n",
      " 7.9498362  2.06146579] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[3.45178366 3.16493323 3.21300463 9.45070468 8.7591459  8.33173528\n",
      " 2.20600069 6.42737392] [56321.8718417] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[56321.8718417] [3.45178366 3.16493323 3.21300463 9.45070468 8.7591459  8.33173528\n",
      " 2.20600069 6.42737392] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[9.58208102 3.06765062 6.30107851 9.56138391 2.079334   9.88368351\n",
      " 7.93913278 4.99526955] [64139.50809944] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[64139.50809944] [9.58208102 3.06765062 6.30107851 9.56138391 2.079334   9.88368351\n",
      " 7.93913278 4.99526955] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[3.44278251 2.09204241 3.67034471 5.5405317  3.84293424 8.57451087\n",
      " 9.26924851 2.9502659 ] [76347.89484793] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[76347.89484793] [3.44278251 2.09204241 3.67034471 5.5405317  3.84293424 8.57451087\n",
      " 9.26924851 2.9502659 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[7.06856866 2.21573269 6.34825617 7.88644084 7.55687063 9.58805763\n",
      " 3.48553571 3.46890728] [71667.30592196] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[71667.30592196] [7.06856866 2.21573269 6.34825617 7.88644084 7.55687063 9.58805763\n",
      " 3.48553571 3.46890728] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more feasible directions at iteration 3825 . [35830.5]\n",
      "[4.14827727 5.9201598  7.34836891 9.24578232 4.57740199 9.50791698\n",
      " 7.98383891 4.3721734 ] [46498.18705846] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[80603.6443331] [3.88774277 2.50114229 8.05284827 9.10398149 4.46322015 9.11396327\n",
      " 8.13186791 4.32635862] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.63909766 7.2714982  6.86832483 2.26021714 3.85604358 7.69309272\n",
      " 2.95277771 3.86600877] [40924.22529014] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[40924.22529014] [4.63909766 7.2714982  6.86832483 2.26021714 3.85604358 7.69309272\n",
      " 2.95277771 3.86600877] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 5958 . [35062.25]\n",
      "[6.18697757 6.56882086 5.81054738 4.11732198 8.37180208 9.82121527\n",
      " 4.39598059 8.38180369] [39240.30250222] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73133.91439825] [5.81653399 2.50043775 6.9145374  4.07390172 8.31132818 9.38436951\n",
      " 4.6971382  8.34205251] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1891 . [20779.5]\n",
      "[8.56216044 4.33776831 7.93039701 4.37255955 9.41797969 8.24600758\n",
      " 2.72828151 6.3260847 ] [54330.92518972] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73864.27040014] [8.3740127  2.50073193 8.27868371 4.34985358 9.35672957 7.93902184\n",
      " 2.87419412 6.34320808] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[3.44278251 2.09204241 3.67034471 5.5405317  3.84293424 8.57451087\n",
      " 9.26924851 2.9502659 ] [76347.89484793] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[76347.89484793] [3.44278251 2.09204241 3.67034471 5.5405317  3.84293424 8.57451087\n",
      " 9.26924851 2.9502659 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1208 . [15990.5]\n",
      "[9.98909637 3.78430854 3.97169146 6.37462202 6.25493522 4.41458679\n",
      " 5.26680229 8.00511753] [56471.51329565] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[71851.21845597] [9.88472421 2.50110065 4.34326224 6.3601863  6.21836978 4.19177182\n",
      " 5.3136753  7.99007719] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1964 . [24302.25]\n",
      "[7.15585233 4.56683534 8.60808435 9.35819159 7.10463724 8.48446358\n",
      " 7.18576991 8.61969735] [55936.90063536] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[79273.97608407] [6.97333329 2.50032633 8.95698646 9.2785242  7.05667578 8.19680057\n",
      " 7.28481466 8.60646599] tensor([[0.9881]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1265 . [17762.25]\n",
      "[3.47162806 3.8712053  4.81450869 7.01926862 4.67299764 6.82779323\n",
      " 4.26650141 3.42291838] [59481.63868677] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[76001.0797121] [3.37384521 2.50093669 5.18416925 6.99318825 4.62433765 6.61225641\n",
      " 4.34093368 3.41363071] tensor([[0.9994]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 318 . [5185.75]\n",
      "[6.06170208 2.87496314 6.90281982 2.70510471 7.12808567 6.70217093\n",
      " 3.84531715 3.59228077] [72725.73585299] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[77536.43766143] [6.02908693 2.50034578 6.9854691  2.70532951 7.11357809 6.63909737\n",
      " 3.86743006 3.59457598] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 104 . [1769.25]\n",
      "[8.76928857 2.62834603 6.056928   3.85091014 8.63540793 6.21728513\n",
      " 8.91450645 9.11925987] [73584.81342595] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[75283.79397261] [8.75878349 2.50030961 6.08619488 3.85075649 8.63215529 6.20038259\n",
      " 8.91775257 9.11919723] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 21 . [310.25]\n",
      "[5.74516326 2.52413459 4.40026463 4.53536448 5.00620419 8.11704295\n",
      " 2.55580086 5.6120337 ] [67214.05487995] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[67501.48045042] [5.74327023 2.50078248 4.40649582 4.53525649 5.00569682 8.11354979\n",
      " 2.55761813 5.61186353] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 5958 . [35062.25]\n",
      "[6.18697757 6.56882086 5.81054738 4.11732198 8.37180208 9.82121527\n",
      " 4.39598059 8.38180369] [39240.30250222] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73133.91439825] [5.81653399 2.50043775 6.9145374  4.07390172 8.31132818 9.38436951\n",
      " 4.6971382  8.34205251] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 3385 . [30726.25]\n",
      "[4.98997542 5.41873414 3.61500436 6.05701488 8.23160727 7.29218542\n",
      " 3.97855472 9.33913974] [41513.2146417] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[70969.79125972] [4.77970352 2.50023216 4.55461747 6.00753589 8.18412828 6.89919191\n",
      " 4.13230351 9.30693383] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[6.41370253 3.84796082 6.6787151  4.50722332 2.41903965 5.59174267\n",
      " 3.64566932 3.20541394] [65431.41057217] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[65431.41057217] [6.41370253 3.84796082 6.6787151  4.50722332 2.41903965 5.59174267\n",
      " 3.64566932 3.20541394] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 2 . [1.25]\n",
      "[5.49215417 8.26276766 6.21403859 8.44036831 9.6772564  6.78353181\n",
      " 2.86848029 5.2141351 ] [35955.10690946] tensor([[0.9996]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[35955.68279589] [5.49213116 8.26255968 6.21428262 8.44030212 9.67720861 6.78346164\n",
      " 2.86848771 5.21412127] tensor([[0.9996]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.31666012 3.86802621 2.32225016 2.61348146 6.03567236 4.31940999\n",
      " 5.86434536 9.52098839] [54154.08178909] tensor([[0.9984]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[54154.08178909] [4.31666012 3.86802621 2.32225016 2.61348146 6.03567236 4.31940999\n",
      " 5.86434536 9.52098839] tensor([[0.9984]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.23961504 8.3725092  5.76464559 8.49609801 5.52093922 8.51519405\n",
      " 6.79952069 5.19043906] [35670.99391096] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[35670.99391096] [2.23961504 8.3725092  5.76464559 8.49609801 5.52093922 8.51519405\n",
      " 6.79952069 5.19043906] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 53 . [782.25]\n",
      "[5.77545084 2.56032368 2.84687668 5.7254832  8.17997311 7.81889402\n",
      " 6.69193553 5.6801515 ] [64199.67835436] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[64935.47018887] [5.77129165 2.50092301 2.8642997  5.72506868 8.17825028 7.81258796\n",
      " 6.6945951  5.68025489] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1 . [0.5]\n",
      "[4.97407362 8.85392438 9.0420079  3.11567614 3.9913667  9.06772489\n",
      " 5.74886625 5.50569836] [39351.36163836] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[39351.45507659] [4.97405783 8.85385785 9.04206675 3.11567116 3.99135926 9.06770881\n",
      " 5.74886286 5.50566913] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[3.42529972 3.12091281 6.22450424 3.86772238 2.05499433 5.28858019\n",
      " 7.22884385 3.77197677] [77040.73649469] tensor([[0.9990]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[77040.73649469] [3.42529972 3.12091281 6.22450424 3.86772238 2.05499433 5.28858019\n",
      " 7.22884385 3.77197677] tensor([[0.9990]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[6.70066522 3.04066453 3.44555526 2.19836695 3.57994109 6.26423593\n",
      " 4.54553226 7.60479519] [62156.25871546] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[62156.25871546] [6.70066522 3.04066453 3.44555526 2.19836695 3.57994109 6.26423593\n",
      " 4.54553226 7.60479519] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 259 . [4265.25]\n",
      "[7.69025148 2.81017694 7.48039875 7.10897734 7.33196814 6.50889107\n",
      " 4.53468652 6.53750297] [73553.81889193] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[77566.59143291] [7.66277899 2.50014193 7.54219935 7.10236787 7.32217783 6.45640536\n",
      " 4.55223879 6.53784903] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.20966833 4.82755058 8.33112372 6.05386772 6.45425962 7.42645223\n",
      " 9.66165679 9.32013025] [58138.74385741] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[70422.04950154] [4.12457293 3.70307509 8.55875774 6.03085477 6.43021108 7.28248928\n",
      " 9.67803401 9.30537712] tensor([[0.6002]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.85018295 8.39532251 4.51192896 6.54405967 9.2382256  8.89249209\n",
      " 8.39590231 9.20570753] [32974.22691955] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[32974.22691955] [4.85018295 8.39532251 4.51192896 6.54405967 9.2382256  8.89249209\n",
      " 8.39590231 9.20570753] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[6.25437912 4.24696162 3.97600304 7.53631715 2.00278013 7.8963462\n",
      " 2.3164338  8.83421963] [48670.73496768] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[48670.73496768] [6.25437912 4.24696162 3.97600304 7.53631715 2.00278013 7.8963462\n",
      " 2.3164338  8.83421963] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 4335 . [38991.75]\n",
      "[7.90470929 6.3330749  8.19267455 4.62380641 8.59141207 7.24683375\n",
      " 9.46541789 6.35831765] [44744.0038634] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[83059.71922682] [7.56371575 2.5003345  8.95474064 4.57663979 8.43036026 6.73817527\n",
      " 9.50830089 6.35927884] tensor([[0.9998]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[8.40079326 9.3841775  2.31882667 5.22013186 6.65516209 8.69986095\n",
      " 6.19268974 9.05128145] [31404.31568233] tensor([[0.9995]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[31404.31568233] [8.40079326 9.3841775  2.31882667 5.22013186 6.65516209 8.69986095\n",
      " 6.19268974 9.05128145] tensor([[0.9995]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1561 . [19296.25]\n",
      "[7.83616152 4.12446818 8.26146515 7.8197602  2.56544452 9.52279921\n",
      " 6.45425932 4.03578958] [59318.15330447] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[77461.87551889] [7.68660329 2.50053863 8.54160659 7.77540492 2.51828605 9.28683399\n",
      " 6.56177822 4.01286953] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.31666012 3.86802621 2.32225016 2.61348146 6.03567236 4.31940999\n",
      " 5.86434536 9.52098839] [54154.08178909] tensor([[0.9984]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[54154.08178909] [4.31666012 3.86802621 2.32225016 2.61348146 6.03567236 4.31940999\n",
      " 5.86434536 9.52098839] tensor([[0.9984]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[6.51327434 3.49569823 8.17139805 2.00121097 8.00449541 7.89619011\n",
      " 6.9767483  8.15783429] [67923.80390554] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[67923.80390554] [6.51327434 3.49569823 8.17139805 2.00121097 8.00449541 7.89619011\n",
      " 6.9767483  8.15783429] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 3385 . [30726.25]\n",
      "[4.98997542 5.41873414 3.61500436 6.05701488 8.23160727 7.29218542\n",
      " 3.97855472 9.33913974] [41513.2146417] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[70969.79125972] [4.77970352 2.50023216 4.55461747 6.00753589 8.18412828 6.89919191\n",
      " 4.13230351 9.30693383] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 4270 . [33452.]\n",
      "[5.109143   5.87968232 2.62457319 4.73146964 4.27903775 8.8700357\n",
      " 8.53360342 4.26528994] [38017.85289092] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[70083.90528667] [4.90039648 2.50066961 3.81896926 4.72933391 4.18034433 8.61724611\n",
      " 8.62636452 4.1905141 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.48406123 2.84138945 6.15259486 2.40760362 7.76871409 9.821738\n",
      " 6.55722958 9.38768387] [69492.16688601] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[69492.16688601] [4.48406123 2.84138945 6.15259486 2.40760362 7.76871409 9.821738\n",
      " 6.55722958 9.38768387] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 4794 . [39029.5]\n",
      "[7.00933451 6.45751096 8.41870936 7.93664641 6.46337112 8.07023648\n",
      " 6.12427831 5.59915807] [44060.61215923] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[81722.6407443] [6.64309565 2.50003638 9.1612619  7.78451669 6.31041073 7.43910579\n",
      " 6.31380175 5.56672223] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 187 . [3788.5]\n",
      "[3.02924659 2.74524202 6.29978985 7.17708261 5.44099747 3.88833632\n",
      " 4.58883198 2.70679481] [82320.70196611] tensor([[0.9989]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[85849.063644] [3.0115428  2.50048433 6.35845087 7.17251176 5.43026482 3.84269922\n",
      " 4.59815405 2.70692833] tensor([[0.9986]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 4074 . [36539.75]\n",
      "[3.03349873 5.98991279 7.60201447 2.65350567 6.81253481 9.09042745\n",
      " 2.53521989 7.94049156] [45875.90841786] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[80169.03990189] [2.72666018 2.50018198 8.38647033 2.63560126 6.75596192 8.53698218\n",
      " 2.80657449 7.90845974] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[5.55660753 5.66597905 2.14178692 8.16738261 6.53428476 7.1771633\n",
      " 3.07581495 2.23260327] [36805.85376187] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[36805.85376187] [5.55660753 5.66597905 2.14178692 8.16738261 6.53428476 7.1771633\n",
      " 3.07581495 2.23260327] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 700 . [9468.]\n",
      "[9.22545751 3.26607377 8.6440655  9.16676316 4.04581057 9.74295102\n",
      " 4.85377851 8.01883358] [63947.86911199] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[72875.3046626] [9.15046639 2.50064684 8.76345582 9.13993516 4.03413992 9.6273425\n",
      " 4.91529838 8.00820475] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 362 . [5015.5]\n",
      "[7.64918917 2.89758583 7.32706996 4.79547298 5.36945525 9.89016881\n",
      " 4.4248102  5.38032035] [67451.08429818] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[72110.67916247] [7.61194163 2.50096885 7.40297655 4.79143355 5.36009426 9.83522697\n",
      " 4.45660878 5.37894365] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 683 . [9764.25]\n",
      "[6.27364679 3.25691991 5.53904012 4.37568764 6.32528265 7.43092455\n",
      " 3.56693159 9.59640105] [63337.89400715] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[72534.06517759] [6.21068804 2.50075104 5.72679977 4.37082007 6.31548088 7.31441212\n",
      " 3.61531123 9.58854767] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1 . [0.75]\n",
      "[5.25904766 8.20173937 7.41872267 8.21652658 2.64033946 8.93704144\n",
      " 9.65310424 5.90079695] [37496.35977709] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[37496.91669488] [5.25903568 8.20153484 7.41882727 8.21649783 2.64033065 8.93704104\n",
      " 9.6530819  5.90075993] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[7.51240616 6.89222388 2.27433044 4.54304472 7.5555095  9.23104571\n",
      " 6.35526986 2.10700777] [32790.12947708] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[32790.12947708] [7.51240616 6.89222388 2.27433044 4.54304472 7.5555095  9.23104571\n",
      " 6.35526986 2.10700777] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 2 . [1.25]\n",
      "[6.39951632 9.79564212 7.35208721 9.51407639 6.46764197 8.22852305\n",
      " 8.03919005 9.79319301] [35139.58532668] tensor([[0.9987]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[35140.0357461] [6.39953456 9.79587122 7.3522088  9.5139997  6.46765067 8.22859748\n",
      " 8.0391128  9.79312224] tensor([[0.9987]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more feasible directions at iteration 2050 . [24182.5]\n",
      "[4.73444547 4.55713543 4.76768044 3.43126218 6.18119505 7.97143628\n",
      " 6.97046524 6.40215195] [51791.4423437] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[74743.13982339] [4.58418915 2.50048681 5.33481887 3.43348264 6.13000496 7.72655738\n",
      " 7.04947791 6.38425255] tensor([[0.6574]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.34722906 7.37824988 2.26491685 9.36257865 8.89383302 6.9966811\n",
      " 6.60915278 8.03253647] [29782.34066008] tensor([[0.9977]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[29782.34066008] [4.34722906 7.37824988 2.26491685 9.36257865 8.89383302 6.9966811\n",
      " 6.60915278 8.03253647] tensor([[0.9977]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 2940 . [24419.]\n",
      "[7.59534288 4.98718601 2.62978363 5.69085127 8.31056625 9.62661298\n",
      " 9.06865306 9.8931685 ] [40713.13116014] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[64748.69682456] [7.42088402 2.50029842 3.43412351 5.67147445 8.28974483 9.51058855\n",
      " 9.14744331 9.8591164 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1469 . [19019.75]\n",
      "[7.74386775 4.06369632 7.97899711 9.64484403 8.47690503 7.27085673\n",
      " 4.46140229 6.17626983] [58826.04635307] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[76845.58820782] [7.60105443 2.50115209 8.26679681 9.58331308 8.42006882 7.01065153\n",
      " 4.55656417 6.18323364] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 5387 . [37682.25]\n",
      "[8.620305   6.52387304 3.88667836 4.19059542 8.64203901 6.0080067\n",
      " 6.58945111 9.07213468] [36424.78214145] tensor([[0.9992]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73797.40611016] [8.2988447  2.50065735 5.25747142 4.18335692 8.53224468 5.44966303\n",
      " 6.65618638 9.01797299] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "Non greedy step\n",
      "Non greedy step\n",
      "Non greedy step\n",
      "[5.0058681  6.10893665 4.29003155 4.94664391 8.75459312 8.26696262\n",
      " 8.48254088 5.12644021] [39828.71859378] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[69404.0648039] [4.78543803 2.87320596 5.29895017 4.91812696 8.62409067 8.00217472\n",
      " 8.53977887 5.12534893] tensor([[0.5970]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[5.14102609 5.07067598 7.82167251 5.88382289 4.616266   5.83559506\n",
      " 2.12023149 2.63866538] [55912.15024953] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[55912.15024953] [5.14102609 5.07067598 7.82167251 5.88382289 4.616266   5.83559506\n",
      " 2.12023149 2.63866538] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 11 . [4.75]\n",
      "[4.35731951 7.89332195 6.7374508  3.37760199 5.12331635 9.62994404\n",
      " 6.41174055 5.39699171] [38478.05310028] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[38483.68246623] [4.35714341 7.89124704 6.73878447 3.37757878 5.123225   9.62994125\n",
      " 6.41175976 5.39673161] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.0492438  3.76322981 5.37982854 5.86245733 4.71079861 5.4551199\n",
      " 6.22584348 9.5382352 ] [65400.96272759] tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[65400.96272759] [2.0492438  3.76322981 5.37982854 5.86245733 4.71079861 5.4551199\n",
      " 6.22584348 9.5382352 ] tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 30 . [502.]\n",
      "[8.35167157 2.53638853 3.62191849 5.94652202 3.26035179 5.44623108\n",
      " 7.99273296 3.63119396] [70880.64336431] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[71354.70670069] [8.34903837 2.50056089 3.63197699 5.94633776 3.25907482 5.44100432\n",
      " 7.99381283 3.63077881] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[6.41370253 3.84796082 6.6787151  4.50722332 2.41903965 5.59174267\n",
      " 3.64566932 3.20541394] [65431.41057217] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[65431.41057217] [6.41370253 3.84796082 6.6787151  4.50722332 2.41903965 5.59174267\n",
      " 3.64566932 3.20541394] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 2957 . [30553.5]\n",
      "[7.73957652 5.27381196 4.09706971 7.71272833 8.64466748 5.33383564\n",
      " 7.07827247 8.3562118 ] [44337.97001957] tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[74196.28999845] [7.53584592 2.50023646 4.92516517 7.64836211 8.55567279 4.9353844\n",
      " 7.12989014 8.33752625] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[8.40079326 9.3841775  2.31882667 5.22013186 6.65516209 8.69986095\n",
      " 6.19268974 9.05128145] [31404.31568233] tensor([[0.9995]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[31404.31568233] [8.40079326 9.3841775  2.31882667 5.22013186 6.65516209 8.69986095\n",
      " 6.19268974 9.05128145] tensor([[0.9995]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 21 . [310.25]\n",
      "[5.74516326 2.52413459 4.40026463 4.53536448 5.00620419 8.11704295\n",
      " 2.55580086 5.6120337 ] [67214.05487995] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[67501.48045042] [5.74327023 2.50078248 4.40649582 4.53525649 5.00569682 8.11354979\n",
      " 2.55761813 5.61186353] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1091 . [14402.75]\n",
      "[8.60608982 3.68830836 7.21414797 6.69336848 4.97587656 9.16413346\n",
      " 8.72876187 7.56794622] [61565.73731706] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[75348.31019911] [8.50271414 2.50081071 7.44483387 6.67206426 4.95196328 9.02398316\n",
      " 8.78252976 7.55368131] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[9.85340823 9.26563236 7.95923307 3.64831335 9.36963147 7.99682817\n",
      " 9.43597667 6.95061809] [36138.82304137] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[36138.82304137] [9.85340823 9.26563236 7.95923307 3.64831335 9.36963147 7.99682817\n",
      " 9.43597667 6.95061809] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[9.85340823 9.26563236 7.95923307 3.64831335 9.36963147 7.99682817\n",
      " 9.43597667 6.95061809] [36138.82304137] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[36138.82304137] [9.85340823 9.26563236 7.95923307 3.64831335 9.36963147 7.99682817\n",
      " 9.43597667 6.95061809] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[7.96228433 8.94982755 8.14662728 4.20372935 6.1152242  7.86171944\n",
      " 6.43489365 6.10629442] [37935.81976833] tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[37935.81976833] [7.96228433 8.94982755 8.14662728 4.20372935 6.1152242  7.86171944\n",
      " 6.43489365 6.10629442] tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1017 . [12360.5]\n",
      "[2.59143951 4.29600963 9.92058926 7.27019206 7.07648428 9.88620264\n",
      " 5.32217423 2.8871521 ] [62166.0936111] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73624.43270559] [ 2.50006705  3.24765356 10.0750888   7.23582834  7.03389869  9.73757635\n",
      "  5.39226952  2.89491508] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 4809 . [33239.]\n",
      "[9.64967842 5.9867215  3.45196606 3.87756789 6.47205822 6.1415491\n",
      " 2.61811839 4.86949291] [37848.1344239] tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[69651.47489208] [9.33061182 2.50098062 4.6917529  3.88559308 6.32758734 5.48915219\n",
      " 2.84422606 4.82802055] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 362 . [5015.5]\n",
      "[7.64918917 2.89758583 7.32706996 4.79547298 5.36945525 9.89016881\n",
      " 4.4248102  5.38032035] [67451.08429818] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[72110.67916247] [7.61194163 2.50096885 7.40297655 4.79143355 5.36009426 9.83522697\n",
      " 4.45660878 5.37894365] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 104 . [1769.25]\n",
      "[8.76928857 2.62834603 6.056928   3.85091014 8.63540793 6.21728513\n",
      " 8.91450645 9.11925987] [73584.81342595] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[75283.79397261] [8.75878349 2.50030961 6.08619488 3.85075649 8.63215529 6.20038259\n",
      " 8.91775257 9.11919723] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.08143832 5.49587179 6.29274552 9.61414548 9.6211931  5.716947\n",
      " 7.03471605 4.12567358] [49443.8653848] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[49443.8653848] [2.08143832 5.49587179 6.29274552 9.61414548 9.6211931  5.716947\n",
      " 7.03471605 4.12567358] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more feasible directions at iteration 1873 . [20208.5]\n",
      "[5.85864825 4.2843192  6.14918803 6.69545209 5.19060212 9.4347719\n",
      " 3.21813603 3.40114842] [53314.72121675] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[72033.53855044] [5.7025641  2.50099281 6.55748854 6.65586859 5.13266552 9.17524245\n",
      " 3.37063917 3.39342084] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 2 . [1.25]\n",
      "[6.39951632 9.79564212 7.35208721 9.51407639 6.46764197 8.22852305\n",
      " 8.03919005 9.79319301] [35139.58532668] tensor([[0.9987]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[35140.0357461] [6.39953456 9.79587122 7.3522088  9.5139997  6.46765067 8.22859748\n",
      " 8.0391128  9.79312224] tensor([[0.9987]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 59 . [58.5]\n",
      "[4.03335766 7.63764846 6.75125065 4.09463841 9.23440151 6.63295844\n",
      " 4.6558113  5.67161037] [39213.01698667] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[39277.94990784] [4.0320016  7.62062666 6.76014853 4.09412373 9.23293555 6.62984053\n",
      " 4.65561004 5.6712365 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.85018295 8.39532251 4.51192896 6.54405967 9.2382256  8.89249209\n",
      " 8.39590231 9.20570753] [32974.22691955] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[32974.22691955] [4.85018295 8.39532251 4.51192896 6.54405967 9.2382256  8.89249209\n",
      " 8.39590231 9.20570753] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 3825 . [35830.5]\n",
      "[4.14827727 5.9201598  7.34836891 9.24578232 4.57740199 9.50791698\n",
      " 7.98383891 4.3721734 ] [46498.18705846] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[80603.6443331] [3.88774277 2.50114229 8.05284827 9.10398149 4.46322015 9.11396327\n",
      " 8.13186791 4.32635862] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "Non greedy step\n",
      "Non greedy step\n",
      "Non greedy step\n",
      "Non greedy step\n",
      "[5.0058681  6.10893665 4.29003155 4.94664391 8.75459312 8.26696262\n",
      " 8.48254088 5.12644021] [39828.71859378] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[69418.25835625] [4.78535448 2.8720593  5.2992319  4.91811894 8.62405139 8.00205224\n",
      " 8.53981612 5.12535542] tensor([[0.5955]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[7.06647414 2.09162001 2.58717138 7.25293221 4.98726764 4.46944891\n",
      " 4.64931443 8.29512877] [72690.09320826] tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[72690.09320826] [7.06647414 2.09162001 2.58717138 7.25293221 4.98726764 4.46944891\n",
      " 4.64931443 8.29512877] tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1561 . [19296.25]\n",
      "[7.83616152 4.12446818 8.26146515 7.8197602  2.56544452 9.52279921\n",
      " 6.45425932 4.03578958] [59318.15330447] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[77461.87551889] [7.68660329 2.50053863 8.54160659 7.77540492 2.51828605 9.28683399\n",
      " 6.56177822 4.01286953] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[3.42529972 3.12091281 6.22450424 3.86772238 2.05499433 5.28858019\n",
      " 7.22884385 3.77197677] [77040.73649469] tensor([[0.9990]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[77040.73649469] [3.42529972 3.12091281 6.22450424 3.86772238 2.05499433 5.28858019\n",
      " 7.22884385 3.77197677] tensor([[0.9990]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 104 . [1769.25]\n",
      "[8.76928857 2.62834603 6.056928   3.85091014 8.63540793 6.21728513\n",
      " 8.91450645 9.11925987] [73584.81342595] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[75283.79397261] [8.75878349 2.50030961 6.08619488 3.85075649 8.63215529 6.20038259\n",
      " 8.91775257 9.11919723] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 653 . [12650.]\n",
      "[2.60843046 3.34646482 5.20140329 9.16694417 6.19210809 3.8501873\n",
      " 7.96071749 8.58640565] [71468.25033644] tensor([[0.9927]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[83527.4686606] [2.55547781 2.50007983 5.42097381 9.14492984 6.1687054  3.71713303\n",
      " 7.97283499 8.57843442] tensor([[0.9487]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 4074 . [36539.75]\n",
      "[3.03349873 5.98991279 7.60201447 2.65350567 6.81253481 9.09042745\n",
      " 2.53521989 7.94049156] [45875.90841786] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[80169.03990189] [2.72666018 2.50018198 8.38647033 2.63560126 6.75596192 8.53698218\n",
      " 2.80657449 7.90845974] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 4074 . [36539.75]\n",
      "[3.03349873 5.98991279 7.60201447 2.65350567 6.81253481 9.09042745\n",
      " 2.53521989 7.94049156] [45875.90841786] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[80169.03990189] [2.72666018 2.50018198 8.38647033 2.63560126 6.75596192 8.53698218\n",
      " 2.80657449 7.90845974] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1 . [0.5]\n",
      "[3.13647961 8.48256887 3.92780283 8.36598977 3.9629386  9.09679814\n",
      " 8.10348771 4.7824802 ] [33025.59400564] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[33025.95353924] [3.13649289 8.48250358 3.92796837 8.36596527 3.9629314  9.09684036\n",
      " 8.10346432 4.78244658] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.23961504 8.3725092  5.76464559 8.49609801 5.52093922 8.51519405\n",
      " 6.79952069 5.19043906] [35670.99391096] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[35670.99391096] [2.23961504 8.3725092  5.76464559 8.49609801 5.52093922 8.51519405\n",
      " 6.79952069 5.19043906] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.47814031 4.29828807 2.39608428 7.11552166 5.27145786 8.97655689\n",
      " 8.30729543 2.4269276 ] [48489.5205714] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[48489.5205714] [2.47814031 4.29828807 2.39608428 7.11552166 5.27145786 8.97655689\n",
      " 8.30729543 2.4269276 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.63909766 7.2714982  6.86832483 2.26021714 3.85604358 7.69309272\n",
      " 2.95277771 3.86600877] [40924.22529014] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[40924.22529014] [4.63909766 7.2714982  6.86832483 2.26021714 3.85604358 7.69309272\n",
      " 2.95277771 3.86600877] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.03244791 8.18813841 4.71158335 7.96056465 9.2849744  7.50539063\n",
      " 4.96642356 4.54650204] [34107.72923143] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[34107.72923143] [2.03244791 8.18813841 4.71158335 7.96056465 9.2849744  7.50539063\n",
      " 4.96642356 4.54650204] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 4074 . [36539.75]\n",
      "[3.03349873 5.98991279 7.60201447 2.65350567 6.81253481 9.09042745\n",
      " 2.53521989 7.94049156] [45875.90841786] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[80169.03990189] [2.72666018 2.50018198 8.38647033 2.63560126 6.75596192 8.53698218\n",
      " 2.80657449 7.90845974] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1265 . [17762.25]\n",
      "[3.47162806 3.8712053  4.81450869 7.01926862 4.67299764 6.82779323\n",
      " 4.26650141 3.42291838] [59481.63868677] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[76001.0797121] [3.37384521 2.50093669 5.18416925 6.99318825 4.62433765 6.61225641\n",
      " 4.34093368 3.41363071] tensor([[0.9994]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[9.11734161 4.62170205 7.94388518 6.60341554 2.49021443 6.55352558\n",
      " 9.78509528 8.66810885] [57563.49352035] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[57563.49352035] [9.11734161 4.62170205 7.94388518 6.60341554 2.49021443 6.55352558\n",
      " 9.78509528 8.66810885] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 187 . [3788.5]\n",
      "[3.02924659 2.74524202 6.29978985 7.17708261 5.44099747 3.88833632\n",
      " 4.58883198 2.70679481] [82320.70196611] tensor([[0.9989]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[85849.063644] [3.0115428  2.50048433 6.35845087 7.17251176 5.43026482 3.84269922\n",
      " 4.59815405 2.70692833] tensor([[0.9986]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.77580922 3.72582298 2.45069058 8.23582683 9.28100114 6.83650414\n",
      " 4.17394074 6.97840703] [52221.80936587] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[52221.80936587] [2.77580922 3.72582298 2.45069058 8.23582683 9.28100114 6.83650414\n",
      " 4.17394074 6.97840703] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more feasible directions at iteration 1131 . [16295.5]\n",
      "[3.05074101 3.76269683 3.68850081 7.14244229 9.71011984 7.10126391\n",
      " 9.5367193  3.80073645] [56722.98247999] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[72202.79328168] [2.97428316 2.50103601 4.04534168 7.12155259 9.6553422  6.98016349\n",
      " 9.5564438  3.81266731] tensor([[0.8226]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 5861 . [43859.]\n",
      "[5.71548708 7.10260945 8.71101024 8.82660091 8.47732381 7.75343561\n",
      " 6.88407201 6.98627806] [41374.41854346] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[84217.32274476] [5.31282262 2.50041561 9.56665646 8.59938069 8.29548261 7.05866631\n",
      " 7.02934684 6.96925644] tensor([[0.9988]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1436 . [21933.5]\n",
      "[3.25988679 4.16643163 6.11047137 9.05088628 3.3246417  7.48755927\n",
      " 9.4141829  8.73158176] [59887.00392935] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[80838.9947756] [3.14989442 2.50049608 6.50069441 9.00313814 3.29755389 7.27971736\n",
      " 9.45466984 8.69606535] tensor([[0.8206]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[5.14102609 5.07067598 7.82167251 5.88382289 4.616266   5.83559506\n",
      " 2.12023149 2.63866538] [55912.15024953] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[55912.15024953] [5.14102609 5.07067598 7.82167251 5.88382289 4.616266   5.83559506\n",
      " 2.12023149 2.63866538] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 259 . [4265.25]\n",
      "[7.69025148 2.81017694 7.48039875 7.10897734 7.33196814 6.50889107\n",
      " 4.53468652 6.53750297] [73553.81889193] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[77566.59143291] [7.66277899 2.50014193 7.54219935 7.10236787 7.32217783 6.45640536\n",
      " 4.55223879 6.53784903] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.26868462 5.67271368 9.03633636 2.63628808 9.05678772 5.00173664\n",
      " 2.85754855 8.3474022 ] [55857.50408395] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[55857.50408395] [2.26868462 5.67271368 9.03633636 2.63628808 9.05678772 5.00173664\n",
      " 2.85754855 8.3474022 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1827 . [25584.]\n",
      "[4.00903864 4.51987833 7.80549751 8.69561418 8.49851633 6.60813089\n",
      " 4.9609437  8.97707959] [58835.30847178] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[83153.37091264] [3.84850768 2.50111523 8.21733073 8.62535911 8.44623396 6.27853186\n",
      " 5.05261907 8.97365864] tensor([[0.6688]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.32452262 2.58871554 9.32749721 9.99315489 4.52452962 7.02169385\n",
      " 4.2840132  2.97129558] [85001.71772456] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[85001.71772456] [2.32452262 2.58871554 9.32749721 9.99315489 4.52452962 7.02169385\n",
      " 4.2840132  2.97129558] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 2 . [1.25]\n",
      "[5.49215417 8.26276766 6.21403859 8.44036831 9.6772564  6.78353181\n",
      " 2.86848029 5.2141351 ] [35955.10690946] tensor([[0.9996]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[35955.68279589] [5.49213116 8.26255968 6.21428262 8.44030212 9.67720861 6.78346164\n",
      " 2.86848771 5.21412127] tensor([[0.9996]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 5612 . [43446.25]\n",
      "[3.66606175 6.9471738  5.86707696 7.66763302 6.5814646  7.81747032\n",
      " 9.11547434 4.66208075] [39596.81582867] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[81820.04212726] [3.3748227  2.50026141 7.06917331 7.52454075 6.39002455 7.33925397\n",
      " 9.15432697 4.61487689] tensor([[0.8549]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.47814031 4.29828807 2.39608428 7.11552166 5.27145786 8.97655689\n",
      " 8.30729543 2.4269276 ] [48489.5205714] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[48489.5205714] [2.47814031 4.29828807 2.39608428 7.11552166 5.27145786 8.97655689\n",
      " 8.30729543 2.4269276 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 3171 . [33310.25]\n",
      "[3.21984115 5.39741914 3.06195252 3.71725886 3.17636821 6.49714444\n",
      " 4.97751651 3.937595  ] [43680.74102663] tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[75018.97540322] [3.03674118 2.50114166 4.06161644 3.72499718 3.08440253 6.05916178\n",
      " 5.09322235 3.87730039] tensor([[0.9956]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 12 . [8.75]\n",
      "[9.83432547 6.94863436 3.83738488 4.29967216 8.70712003 7.72073973\n",
      " 3.80252696 6.15572894] [34307.59540235] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[34317.50532395] [9.83400292 6.94598521 3.83953128 4.29966309 8.70694159 7.72046711\n",
      " 3.80272417 6.15559903] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[6.26869478 2.7793247  2.85418812 9.87090656 8.23408446 4.93358931\n",
      " 2.15131749 8.82074611] [62247.78215649] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[62247.78215649] [6.26869478 2.7793247  2.85418812 9.87090656 8.23408446 4.93358931\n",
      " 2.15131749 8.82074611] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.12717718 4.24935594 4.83282894 9.48940368 6.69310519 4.95351523\n",
      " 4.76269905 3.49531252] [58366.38822245] tensor([[0.9992]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[58366.38822245] [2.12717718 4.24935594 4.83282894 9.48940368 6.69310519 4.95351523\n",
      " 4.76269905 3.49531252] tensor([[0.9992]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 3199 . [30480.75]\n",
      "[9.69966537 5.41007866 9.69943169 7.06700543 5.13563692 8.98541662\n",
      " 5.00715795 6.94953862] [48786.33285768] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[77963.25111508] [ 9.38778778  2.50087256 10.11178242  6.9770608   5.06047324  8.48919413\n",
      "  5.21854472  6.91391644] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 2677 . [29165.5]\n",
      "[8.79607643 5.13182443 8.46903993 8.16844059 6.22613906 7.79248743\n",
      " 6.81633537 8.79534181] [51199.30745257] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[79457.78083999] [8.55048124 2.50068352 8.93591744 8.0820881  6.16572697 7.38485138\n",
      " 6.93827011 8.76333707] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[3.57861903 6.280178   8.65911151 9.68024777 5.08156352 7.32347276\n",
      " 7.9498362  2.06146579] [48111.02279279] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[48111.02279279] [3.57861903 6.280178   8.65911151 9.68024777 5.08156352 7.32347276\n",
      " 7.9498362  2.06146579] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 108 . [1759.5]\n",
      "[7.80140724 2.62842748 5.54328779 9.13336153 7.01419669 5.73058897\n",
      " 4.2462284  6.93044481] [71446.04961701] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73105.28787059] [7.79091898 2.50056969 5.57366675 9.12978068 7.01033335 5.70911804\n",
      " 4.25315685 6.93010543] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 187 . [3788.5]\n",
      "[3.02924659 2.74524202 6.29978985 7.17708261 5.44099747 3.88833632\n",
      " 4.58883198 2.70679481] [82320.70196611] tensor([[0.9989]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[85849.063644] [3.0115428  2.50048433 6.35845087 7.17251176 5.43026482 3.84269922\n",
      " 4.59815405 2.70692833] tensor([[0.9986]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 5845 . [39176.75]\n",
      "[4.82380255 6.74118993 8.26776052 5.40919866 6.95306475 9.69790705\n",
      " 2.83948251 5.78381106] [42007.3568367] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[78925.36037793] [4.4090305  2.50080525 9.10555224 5.29160709 6.82691421 9.02145405\n",
      " 3.21750298 5.75721313] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.63909766 7.2714982  6.86832483 2.26021714 3.85604358 7.69309272\n",
      " 2.95277771 3.86600877] [40924.22529014] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[40924.22529014] [4.63909766 7.2714982  6.86832483 2.26021714 3.85604358 7.69309272\n",
      " 2.95277771 3.86600877] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[7.73649831 6.41277343 6.98165062 9.38499875 7.25833299 9.01180244\n",
      " 2.22250342 2.63210608] [39716.28238701] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[39716.28238701] [7.73649831 6.41277343 6.98165062 9.38499875 7.25833299 9.01180244\n",
      " 2.22250342 2.63210608] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 6 . [3.25]\n",
      "[8.00038394 8.01040703 8.39539127 3.58537272 3.25838512 8.3279503\n",
      " 8.18537281 9.91936961] [37856.44237771] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[37860.44581604] [8.00020937 8.00900868 8.39595524 3.5853498  3.25841723 8.327774\n",
      " 8.18529484 9.91912628] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non greedy step\n",
      "Non greedy step\n",
      "[5.0058681  6.10893665 4.29003155 4.94664391 8.75459312 8.26696262\n",
      " 8.48254088 5.12644021] [39828.71859378] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[69389.8767355] [4.78552155 2.87435239 5.29866846 4.91813498 8.62412995 8.00229716\n",
      " 8.53974163 5.12534245] tensor([[0.5984]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 450 . [6165.5]\n",
      "[8.73286359 2.99412554 8.71650172 5.39791854 9.41658602 9.58566976\n",
      " 4.35316024 4.88773315] [66893.50596097] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[72643.81225492] [8.6828641  2.50094283 8.79370624 5.38962954 9.39910275 9.51523977\n",
      " 4.39186969 4.89456629] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 5387 . [37682.25]\n",
      "[8.620305   6.52387304 3.88667836 4.19059542 8.64203901 6.0080067\n",
      " 6.58945111 9.07213468] [36424.78214145] tensor([[0.9992]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73797.40611016] [8.2988447  2.50065735 5.25747142 4.18335692 8.53224468 5.44966303\n",
      " 6.65618638 9.01797299] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 5059 . [39549.5]\n",
      "[8.04243762 6.54567728 9.72284694 2.59465914 4.73874635 8.58703844\n",
      " 3.40612364 8.84626268] [43694.08386087] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[81600.37690362] [ 7.59490922  2.50051912 10.39065841  2.57255918  4.68136596  7.79869293\n",
      "  3.71574977  8.75514366] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.75209249 3.86500166 2.10559135 4.8232818  7.21272293 6.38729759\n",
      " 8.33755428 9.08530604] [51020.46621753] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[51020.46621753] [4.75209249 3.86500166 2.10559135 4.8232818  7.21272293 6.38729759\n",
      " 8.33755428 9.08530604] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.85018295 8.39532251 4.51192896 6.54405967 9.2382256  8.89249209\n",
      " 8.39590231 9.20570753] [32974.22691955] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[32974.22691955] [4.85018295 8.39532251 4.51192896 6.54405967 9.2382256  8.89249209\n",
      " 8.39590231 9.20570753] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[6.41370253 3.84796082 6.6787151  4.50722332 2.41903965 5.59174267\n",
      " 3.64566932 3.20541394] [65431.41057217] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[65431.41057217] [6.41370253 3.84796082 6.6787151  4.50722332 2.41903965 5.59174267\n",
      " 3.64566932 3.20541394] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1 . [0.25]\n",
      "[9.37117828 8.91561452 9.63227616 3.66125118 9.98231288 9.72152193\n",
      " 9.9229497  7.03697657] [37082.04345813] tensor([[1.]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[37082.08387827] [9.37115685 8.91559058 9.63229089 3.66124391 9.98229796 9.72156033\n",
      " 9.92291858 7.03696799] tensor([[1.]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 653 . [12650.]\n",
      "[2.60843046 3.34646482 5.20140329 9.16694417 6.19210809 3.8501873\n",
      " 7.96071749 8.58640565] [71468.25033644] tensor([[0.9927]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[83527.4686606] [2.55547781 2.50007983 5.42097381 9.14492984 6.1687054  3.71713303\n",
      " 7.97283499 8.57843442] tensor([[0.9487]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 6 . [115.25]\n",
      "[8.80520968 2.50792814 8.8845873  9.7151944  9.88507815 3.43088659\n",
      " 2.56398478 7.8957911 ] [83292.2198343] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[83402.05658543] [8.80448928 2.50015615 8.88598183 9.71492461 9.88478118 3.42924493\n",
      " 2.56439454 7.89585466] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1356 . [17577.5]\n",
      "[3.29835214 3.93847072 5.76595876 8.42154026 8.73202246 8.79435178\n",
      " 4.57508597 9.83259606] [57190.51116966] tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73784.60493494] [3.19098009 2.50051314 6.10624844 8.37599599 8.71175908 8.61673394\n",
      " 4.66307057 9.82781261] tensor([[0.9908]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 2 . [1.25]\n",
      "[5.49215417 8.26276766 6.21403859 8.44036831 9.6772564  6.78353181\n",
      " 2.86848029 5.2141351 ] [35955.10690946] tensor([[0.9996]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[35955.68279589] [5.49213116 8.26255968 6.21428262 8.44030212 9.67720861 6.78346164\n",
      " 2.86848771 5.21412127] tensor([[0.9996]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 362 . [5015.5]\n",
      "[7.64918917 2.89758583 7.32706996 4.79547298 5.36945525 9.89016881\n",
      " 4.4248102  5.38032035] [67451.08429818] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[72110.67916247] [7.61194163 2.50096885 7.40297655 4.79143355 5.36009426 9.83522697\n",
      " 4.45660878 5.37894365] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 445 . [9622.]\n",
      "[3.84330328 3.11903088 8.63367165 8.88974916 8.81972552 3.69938965\n",
      " 8.75334237 8.74292895] [82869.63799197] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[92073.68628317] [3.79774661 2.50143278 8.75329661 8.87230654 8.79869793 3.59618521\n",
      " 8.76162157 8.74398984] tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 6 . [3.25]\n",
      "[8.00038394 8.01040703 8.39539127 3.58537272 3.25838512 8.3279503\n",
      " 8.18537281 9.91936961] [37856.44237771] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[37860.44581604] [8.00020937 8.00900868 8.39595524 3.5853498  3.25841723 8.327774\n",
      " 8.18529484 9.91912628] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 3790 . [32713.]\n",
      "[7.91940831 5.75010687 4.99891093 8.70989058 9.0463968  6.72622391\n",
      " 6.36021882 9.53906911] [41677.91626755] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73813.92491788] [7.66075245 2.50069649 5.89448827 8.59548572 8.96526736 6.28447347\n",
      " 6.46681529 9.5121552 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[3.07421164 7.20075127 6.37380909 4.27023187 5.28944986 7.86059427\n",
      " 6.30914519 7.51564167] [39995.00744805] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[77746.1031659] [2.76783816 2.95634797 7.57937221 4.2188326  5.19624537 7.26752916\n",
      " 6.43253797 7.40406628] tensor([[0.6017]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 5387 . [37682.25]\n",
      "[8.620305   6.52387304 3.88667836 4.19059542 8.64203901 6.0080067\n",
      " 6.58945111 9.07213468] [36424.78214145] tensor([[0.9992]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[73797.40611016] [8.2988447  2.50065735 5.25747142 4.18335692 8.53224468 5.44966303\n",
      " 6.65618638 9.01797299] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[4.20966833 4.82755058 8.33112372 6.05386772 6.45425962 7.42645223\n",
      " 9.66165679 9.32013025] [58138.74385741] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[70422.04950154] [4.12457293 3.70307509 8.55875774 6.03085477 6.43021108 7.28248928\n",
      " 9.67803401 9.30537712] tensor([[0.6002]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[8.76254164 2.40324077 8.77518014 3.82322874 4.85104019 4.60577037\n",
      " 8.11653639 8.55373399] [88072.41631271] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[88072.41631271] [8.76254164 2.40324077 8.77518014 3.82322874 4.85104019 4.60577037\n",
      " 8.11653639 8.55373399] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1793 . [25092.75]\n",
      "[7.55770164 4.50361243 8.21981413 9.34081355 7.3479328  6.0781645\n",
      " 8.63311071 5.71729505] [59185.27211982] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[83371.67919515] [7.39078563 2.50059955 8.59522579 9.2726016  7.26540399 5.76620497\n",
      " 8.68151246 5.71658802] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[3.62956963 2.36034051 4.58837303 5.59544987 7.97397502 3.143072\n",
      " 7.47271901 8.66850752] [82752.4400898] tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[82752.4400898] [3.62956963 2.36034051 4.58837303 5.59544987 7.97397502 3.143072\n",
      " 7.47271901 8.66850752] tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 159 . [2980.5]\n",
      "[3.83671996 2.70671316 8.90347259 7.96412085 2.9236093  9.71053206\n",
      " 9.80305837 5.86719892] [80683.8276401] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[83476.75578741] [3.8206675  2.50115551 8.93736124 7.95908789 2.91901061 9.68578389\n",
      " 9.81174733 5.86494581] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more feasible directions at iteration 1719 . [25592.75]\n",
      "[6.36561609 4.46092386 7.76467428 5.86205955 9.90076986 4.4588183\n",
      " 6.92587464 5.14131829] [61658.99897107] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[86153.80835399] [6.20428381 2.50037154 8.18003764 5.82915762 9.80571404 4.11784066\n",
      " 6.96757846 5.16175023] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[7.63168609 5.96373284 2.15863472 3.58381163 6.85386144 7.45234988\n",
      " 8.66903784 3.46879002] [35474.39655556] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[35474.39655556] [7.63168609 5.96373284 2.15863472 3.58381163 6.85386144 7.45234988\n",
      " 8.66903784 3.46879002] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 59 . [58.5]\n",
      "[4.03335766 7.63764846 6.75125065 4.09463841 9.23440151 6.63295844\n",
      " 4.6558113  5.67161037] [39213.01698667] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[39277.94990784] [4.0320016  7.62062666 6.76014853 4.09412373 9.23293555 6.62984053\n",
      " 4.65561004 5.6712365 ] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1 . [0.5]\n",
      "[4.97407362 8.85392438 9.0420079  3.11567614 3.9913667  9.06772489\n",
      " 5.74886625 5.50569836] [39351.36163836] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[39351.45507659] [4.97405783 8.85385785 9.04206675 3.11567116 3.99135926 9.06770881\n",
      " 5.74886286 5.50566913] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1873 . [20208.5]\n",
      "[5.85864825 4.2843192  6.14918803 6.69545209 5.19060212 9.4347719\n",
      " 3.21813603 3.40114842] [53314.72121675] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[72033.53855044] [5.7025641  2.50099281 6.55748854 6.65586859 5.13266552 9.17524245\n",
      " 3.37063917 3.39342084] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[4.85018295 8.39532251 4.51192896 6.54405967 9.2382256  8.89249209\n",
      " 8.39590231 9.20570753] [32974.22691955] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[32974.22691955] [4.85018295 8.39532251 4.51192896 6.54405967 9.2382256  8.89249209\n",
      " 8.39590231 9.20570753] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 1 . [0.5]\n",
      "[6.31474184 7.9625008  9.62109694 5.82377057 6.71586524 9.89056473\n",
      " 6.83650778 5.31607151] [39798.29390913] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[39798.77475111] [6.31471054 7.96229158 9.62114224 5.82374877 6.71584865 9.8905481\n",
      " 6.83651392 5.31605701] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "Non greedy step\n",
      "[3.07421164 7.20075127 6.37380909 4.27023187 5.28944986 7.86059427\n",
      " 6.30914519 7.51564167] [39995.00744805] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[77762.37701118] [2.76774442 2.95511796 7.5796337  4.21882247 5.19621811 7.26734621\n",
      " 6.43259016 7.40405664] tensor([[0.5997]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.37535311 6.02267168 8.37377495 4.53309991 7.7243974  6.89612848\n",
      " 4.43453858 3.57922737] [50140.49985484] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[50140.49985484] [2.37535311 6.02267168 8.37377495 4.53309991 7.7243974  6.89612848\n",
      " 4.43453858 3.57922737] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[9.7911429  2.02615873 4.52231431 3.79395457 6.29207474 8.47450088\n",
      " 6.39128321 2.82500429] [71448.21420179] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[71448.21420179] [9.7911429  2.02615873 4.52231431 3.79395457 6.29207474 8.47450088\n",
      " 6.39128321 2.82500429] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "No more feasible directions at iteration 0 . [0.]\n",
      "[2.08143832 5.49587179 6.29274552 9.61414548 9.6211931  5.716947\n",
      " 7.03471605 4.12567358] [49443.8653848] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n",
      "[49443.8653848] [2.08143832 5.49587179 6.29274552 9.61414548 9.6211931  5.716947\n",
      " 7.03471605 4.12567358] tensor([[1.0000]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "samples = filtered_df.iloc[np.random.choice(len(filtered_df), 197), :8]\n",
    "for i in range(len(samples)):\n",
    "    X0 = np.array(samples.iloc[i])\n",
    "    result = coordinateAscentQuad(classif, ridge, X0, confidence = .6)\n",
    "    print(X0, ridge.predict(poly.fit_transform([X0])), classif(torch.from_numpy(poly.fit_transform([X0]))))\n",
    "    print(ridge.predict(poly.fit_transform([result])), result, classif(torch.from_numpy(poly.fit_transform([result]))))\n",
    "    results.append((X0, result, ridge.predict(poly.fit_transform([result])), ridge.predict(poly.fit_transform([X0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e1a8b42b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([3.84330328, 3.11903088, 8.63367165, 8.88974916, 8.81972552,\n",
       "         3.69938965, 8.75334237, 8.74292895]),\n",
       "  array([3.79774661, 2.50143278, 8.75329661, 8.87230654, 8.79869793,\n",
       "         3.59618521, 8.76162157, 8.74398984]),\n",
       "  array([92073.68628317]),\n",
       "  array([82869.63799197])),\n",
       " (array([8.76254164, 2.40324077, 8.77518014, 3.82322874, 4.85104019,\n",
       "         4.60577037, 8.11653639, 8.55373399]),\n",
       "  array([8.76254164, 2.40324077, 8.77518014, 3.82322874, 4.85104019,\n",
       "         4.60577037, 8.11653639, 8.55373399]),\n",
       "  array([88072.41631271]),\n",
       "  array([88072.41631271])),\n",
       " (array([4.20404871, 6.23903807, 9.53722911, 4.87370122, 5.62376644,\n",
       "         8.01605349, 3.50606934, 3.87734483]),\n",
       "  array([ 3.85391216,  2.50117071, 10.18919504,  4.7952754 ,  5.47010527,\n",
       "          7.30372936,  3.7533133 ,  3.86307765]),\n",
       "  array([86517.2008934]),\n",
       "  array([48474.36513678])),\n",
       " (array([6.36561609, 4.46092386, 7.76467428, 5.86205955, 9.90076986,\n",
       "         4.4588183 , 6.92587464, 5.14131829]),\n",
       "  array([6.20428381, 2.50037154, 8.18003764, 5.82915762, 9.80571404,\n",
       "         4.11784066, 6.96757846, 5.16175023]),\n",
       "  array([86153.80835399]),\n",
       "  array([61658.99897107])),\n",
       " (array([3.02924659, 2.74524202, 6.29978985, 7.17708261, 5.44099747,\n",
       "         3.88833632, 4.58883198, 2.70679481]),\n",
       "  array([3.0115428 , 2.50048433, 6.35845087, 7.17251176, 5.43026482,\n",
       "         3.84269922, 4.59815405, 2.70692833]),\n",
       "  array([85849.063644]),\n",
       "  array([82320.70196611])),\n",
       " (array([3.02924659, 2.74524202, 6.29978985, 7.17708261, 5.44099747,\n",
       "         3.88833632, 4.58883198, 2.70679481]),\n",
       "  array([3.0115428 , 2.50048433, 6.35845087, 7.17251176, 5.43026482,\n",
       "         3.84269922, 4.59815405, 2.70692833]),\n",
       "  array([85849.063644]),\n",
       "  array([82320.70196611])),\n",
       " (array([3.02924659, 2.74524202, 6.29978985, 7.17708261, 5.44099747,\n",
       "         3.88833632, 4.58883198, 2.70679481]),\n",
       "  array([3.0115428 , 2.50048433, 6.35845087, 7.17251176, 5.43026482,\n",
       "         3.84269922, 4.59815405, 2.70692833]),\n",
       "  array([85849.063644]),\n",
       "  array([82320.70196611])),\n",
       " (array([2.32452262, 2.58871554, 9.32749721, 9.99315489, 4.52452962,\n",
       "         7.02169385, 4.2840132 , 2.97129558]),\n",
       "  array([2.32452262, 2.58871554, 9.32749721, 9.99315489, 4.52452962,\n",
       "         7.02169385, 4.2840132 , 2.97129558]),\n",
       "  array([85001.71772456]),\n",
       "  array([85001.71772456])),\n",
       " (array([5.71548708, 7.10260945, 8.71101024, 8.82660091, 8.47732381,\n",
       "         7.75343561, 6.88407201, 6.98627806]),\n",
       "  array([5.31282262, 2.50041561, 9.56665646, 8.59938069, 8.29548261,\n",
       "         7.05866631, 7.02934684, 6.96925644]),\n",
       "  array([84217.32274476]),\n",
       "  array([41374.41854346])),\n",
       " (array([2.60843046, 3.34646482, 5.20140329, 9.16694417, 6.19210809,\n",
       "         3.8501873 , 7.96071749, 8.58640565]),\n",
       "  array([2.55547781, 2.50007983, 5.42097381, 9.14492984, 6.1687054 ,\n",
       "         3.71713303, 7.97283499, 8.57843442]),\n",
       "  array([83527.4686606]),\n",
       "  array([71468.25033644])),\n",
       " (array([2.60843046, 3.34646482, 5.20140329, 9.16694417, 6.19210809,\n",
       "         3.8501873 , 7.96071749, 8.58640565]),\n",
       "  array([2.55547781, 2.50007983, 5.42097381, 9.14492984, 6.1687054 ,\n",
       "         3.71713303, 7.97283499, 8.57843442]),\n",
       "  array([83527.4686606]),\n",
       "  array([71468.25033644])),\n",
       " (array([3.83671996, 2.70671316, 8.90347259, 7.96412085, 2.9236093 ,\n",
       "         9.71053206, 9.80305837, 5.86719892]),\n",
       "  array([3.8206675 , 2.50115551, 8.93736124, 7.95908789, 2.91901061,\n",
       "         9.68578389, 9.81174733, 5.86494581]),\n",
       "  array([83476.75578741]),\n",
       "  array([80683.8276401])),\n",
       " (array([8.80520968, 2.50792814, 8.8845873 , 9.7151944 , 9.88507815,\n",
       "         3.43088659, 2.56398478, 7.8957911 ]),\n",
       "  array([8.80448928, 2.50015615, 8.88598183, 9.71492461, 9.88478118,\n",
       "         3.42924493, 2.56439454, 7.89585466]),\n",
       "  array([83402.05658543]),\n",
       "  array([83292.2198343])),\n",
       " (array([7.55770164, 4.50361243, 8.21981413, 9.34081355, 7.3479328 ,\n",
       "         6.0781645 , 8.63311071, 5.71729505]),\n",
       "  array([7.39078563, 2.50059955, 8.59522579, 9.2726016 , 7.26540399,\n",
       "         5.76620497, 8.68151246, 5.71658802]),\n",
       "  array([83371.67919515]),\n",
       "  array([59185.27211982])),\n",
       " (array([7.55770164, 4.50361243, 8.21981413, 9.34081355, 7.3479328 ,\n",
       "         6.0781645 , 8.63311071, 5.71729505]),\n",
       "  array([7.39078563, 2.50059955, 8.59522579, 9.2726016 , 7.26540399,\n",
       "         5.76620497, 8.68151246, 5.71658802]),\n",
       "  array([83371.67919515]),\n",
       "  array([59185.27211982])),\n",
       " (array([4.00903864, 4.51987833, 7.80549751, 8.69561418, 8.49851633,\n",
       "         6.60813089, 4.9609437 , 8.97707959]),\n",
       "  array([3.84850768, 2.50111523, 8.21733073, 8.62535911, 8.44623396,\n",
       "         6.27853186, 5.05261907, 8.97365864]),\n",
       "  array([83153.37091264]),\n",
       "  array([58835.30847178])),\n",
       " (array([7.90470929, 6.3330749 , 8.19267455, 4.62380641, 8.59141207,\n",
       "         7.24683375, 9.46541789, 6.35831765]),\n",
       "  array([7.56371575, 2.5003345 , 8.95474064, 4.57663979, 8.43036026,\n",
       "         6.73817527, 9.50830089, 6.35927884]),\n",
       "  array([83059.71922682]),\n",
       "  array([44744.0038634])),\n",
       " (array([3.62956963, 2.36034051, 4.58837303, 5.59544987, 7.97397502,\n",
       "         3.143072  , 7.47271901, 8.66850752]),\n",
       "  array([3.62956963, 2.36034051, 4.58837303, 5.59544987, 7.97397502,\n",
       "         3.143072  , 7.47271901, 8.66850752]),\n",
       "  array([82752.4400898]),\n",
       "  array([82752.4400898])),\n",
       " (array([3.66606175, 6.9471738 , 5.86707696, 7.66763302, 6.5814646 ,\n",
       "         7.81747032, 9.11547434, 4.66208075]),\n",
       "  array([3.3748227 , 2.50026141, 7.06917331, 7.52454075, 6.39002455,\n",
       "         7.33925397, 9.15432697, 4.61487689]),\n",
       "  array([81820.04212726]),\n",
       "  array([39596.81582867])),\n",
       " (array([7.00933451, 6.45751096, 8.41870936, 7.93664641, 6.46337112,\n",
       "         8.07023648, 6.12427831, 5.59915807]),\n",
       "  array([6.64309565, 2.50003638, 9.1612619 , 7.78451669, 6.31041073,\n",
       "         7.43910579, 6.31380175, 5.56672223]),\n",
       "  array([81722.6407443]),\n",
       "  array([44060.61215923])),\n",
       " (array([8.04243762, 6.54567728, 9.72284694, 2.59465914, 4.73874635,\n",
       "         8.58703844, 3.40612364, 8.84626268]),\n",
       "  array([ 7.59490922,  2.50051912, 10.39065841,  2.57255918,  4.68136596,\n",
       "          7.79869293,  3.71574977,  8.75514366]),\n",
       "  array([81600.37690362]),\n",
       "  array([43694.08386087])),\n",
       " (array([3.15625135, 5.03102599, 4.70969599, 3.06083945, 9.29774736,\n",
       "         4.79142794, 8.05243392, 4.79614511]),\n",
       "  array([2.99185225, 2.500838  , 5.44728979, 3.06624515, 9.18228938,\n",
       "         4.43359063, 8.06538962, 4.81102135]),\n",
       "  array([81346.81495921]),\n",
       "  array([50944.89244003])),\n",
       " (array([3.25988679, 4.16643163, 6.11047137, 9.05088628, 3.3246417 ,\n",
       "         7.48755927, 9.4141829 , 8.73158176]),\n",
       "  array([3.14989442, 2.50049608, 6.50069441, 9.00313814, 3.29755389,\n",
       "         7.27971736, 9.45466984, 8.69606535]),\n",
       "  array([80838.9947756]),\n",
       "  array([59887.00392935])),\n",
       " (array([4.14827727, 5.9201598 , 7.34836891, 9.24578232, 4.57740199,\n",
       "         9.50791698, 7.98383891, 4.3721734 ]),\n",
       "  array([3.88774277, 2.50114229, 8.05284827, 9.10398149, 4.46322015,\n",
       "         9.11396327, 8.13186791, 4.32635862]),\n",
       "  array([80603.6443331]),\n",
       "  array([46498.18705846])),\n",
       " (array([4.14827727, 5.9201598 , 7.34836891, 9.24578232, 4.57740199,\n",
       "         9.50791698, 7.98383891, 4.3721734 ]),\n",
       "  array([3.88774277, 2.50114229, 8.05284827, 9.10398149, 4.46322015,\n",
       "         9.11396327, 8.13186791, 4.32635862]),\n",
       "  array([80603.6443331]),\n",
       "  array([46498.18705846])),\n",
       " (array([3.03349873, 5.98991279, 7.60201447, 2.65350567, 6.81253481,\n",
       "         9.09042745, 2.53521989, 7.94049156]),\n",
       "  array([2.72666018, 2.50018198, 8.38647033, 2.63560126, 6.75596192,\n",
       "         8.53698218, 2.80657449, 7.90845974]),\n",
       "  array([80169.03990189]),\n",
       "  array([45875.90841786])),\n",
       " (array([3.03349873, 5.98991279, 7.60201447, 2.65350567, 6.81253481,\n",
       "         9.09042745, 2.53521989, 7.94049156]),\n",
       "  array([2.72666018, 2.50018198, 8.38647033, 2.63560126, 6.75596192,\n",
       "         8.53698218, 2.80657449, 7.90845974]),\n",
       "  array([80169.03990189]),\n",
       "  array([45875.90841786])),\n",
       " (array([3.03349873, 5.98991279, 7.60201447, 2.65350567, 6.81253481,\n",
       "         9.09042745, 2.53521989, 7.94049156]),\n",
       "  array([2.72666018, 2.50018198, 8.38647033, 2.63560126, 6.75596192,\n",
       "         8.53698218, 2.80657449, 7.90845974]),\n",
       "  array([80169.03990189]),\n",
       "  array([45875.90841786])),\n",
       " (array([3.03349873, 5.98991279, 7.60201447, 2.65350567, 6.81253481,\n",
       "         9.09042745, 2.53521989, 7.94049156]),\n",
       "  array([2.72666018, 2.50018198, 8.38647033, 2.63560126, 6.75596192,\n",
       "         8.53698218, 2.80657449, 7.90845974]),\n",
       "  array([80169.03990189]),\n",
       "  array([45875.90841786])),\n",
       " (array([3.03349873, 5.98991279, 7.60201447, 2.65350567, 6.81253481,\n",
       "         9.09042745, 2.53521989, 7.94049156]),\n",
       "  array([2.72666018, 2.50018198, 8.38647033, 2.63560126, 6.75596192,\n",
       "         8.53698218, 2.80657449, 7.90845974]),\n",
       "  array([80169.03990189]),\n",
       "  array([45875.90841786])),\n",
       " (array([8.79607643, 5.13182443, 8.46903993, 8.16844059, 6.22613906,\n",
       "         7.79248743, 6.81633537, 8.79534181]),\n",
       "  array([8.55048124, 2.50068352, 8.93591744, 8.0820881 , 6.16572697,\n",
       "         7.38485138, 6.93827011, 8.76333707]),\n",
       "  array([79457.78083999]),\n",
       "  array([51199.30745257])),\n",
       " (array([7.15585233, 4.56683534, 8.60808435, 9.35819159, 7.10463724,\n",
       "         8.48446358, 7.18576991, 8.61969735]),\n",
       "  array([6.97333329, 2.50032633, 8.95698646, 9.2785242 , 7.05667578,\n",
       "         8.19680057, 7.28481466, 8.60646599]),\n",
       "  array([79273.97608407]),\n",
       "  array([55936.90063536])),\n",
       " (array([7.15585233, 4.56683534, 8.60808435, 9.35819159, 7.10463724,\n",
       "         8.48446358, 7.18576991, 8.61969735]),\n",
       "  array([6.97333329, 2.50032633, 8.95698646, 9.2785242 , 7.05667578,\n",
       "         8.19680057, 7.28481466, 8.60646599]),\n",
       "  array([79273.97608407]),\n",
       "  array([55936.90063536])),\n",
       " (array([4.82380255, 6.74118993, 8.26776052, 5.40919866, 6.95306475,\n",
       "         9.69790705, 2.83948251, 5.78381106]),\n",
       "  array([4.4090305 , 2.50080525, 9.10555224, 5.29160709, 6.82691421,\n",
       "         9.02145405, 3.21750298, 5.75721313]),\n",
       "  array([78925.36037793]),\n",
       "  array([42007.3568367])),\n",
       " (array([4.82380255, 6.74118993, 8.26776052, 5.40919866, 6.95306475,\n",
       "         9.69790705, 2.83948251, 5.78381106]),\n",
       "  array([4.4090305 , 2.50080525, 9.10555224, 5.29160709, 6.82691421,\n",
       "         9.02145405, 3.21750298, 5.75721313]),\n",
       "  array([78925.36037793]),\n",
       "  array([42007.3568367])),\n",
       " (array([4.82380255, 6.74118993, 8.26776052, 5.40919866, 6.95306475,\n",
       "         9.69790705, 2.83948251, 5.78381106]),\n",
       "  array([4.4090305 , 2.50080525, 9.10555224, 5.29160709, 6.82691421,\n",
       "         9.02145405, 3.21750298, 5.75721313]),\n",
       "  array([78925.36037793]),\n",
       "  array([42007.3568367])),\n",
       " (array([9.69966537, 5.41007866, 9.69943169, 7.06700543, 5.13563692,\n",
       "         8.98541662, 5.00715795, 6.94953862]),\n",
       "  array([ 9.38778778,  2.50087256, 10.11178242,  6.9770608 ,  5.06047324,\n",
       "          8.48919413,  5.21854472,  6.91391644]),\n",
       "  array([77963.25111508]),\n",
       "  array([48786.33285768])),\n",
       " (array([3.07421164, 7.20075127, 6.37380909, 4.27023187, 5.28944986,\n",
       "         7.86059427, 6.30914519, 7.51564167]),\n",
       "  array([2.76774442, 2.95511796, 7.5796337 , 4.21882247, 5.19621811,\n",
       "         7.26734621, 6.43259016, 7.40405664]),\n",
       "  array([77762.37701118]),\n",
       "  array([39995.00744805])),\n",
       " (array([3.07421164, 7.20075127, 6.37380909, 4.27023187, 5.28944986,\n",
       "         7.86059427, 6.30914519, 7.51564167]),\n",
       "  array([2.76783816, 2.95634797, 7.57937221, 4.2188326 , 5.19624537,\n",
       "         7.26752916, 6.43253797, 7.40406628]),\n",
       "  array([77746.1031659]),\n",
       "  array([39995.00744805])),\n",
       " (array([7.69025148, 2.81017694, 7.48039875, 7.10897734, 7.33196814,\n",
       "         6.50889107, 4.53468652, 6.53750297]),\n",
       "  array([7.66277899, 2.50014193, 7.54219935, 7.10236787, 7.32217783,\n",
       "         6.45640536, 4.55223879, 6.53784903]),\n",
       "  array([77566.59143291]),\n",
       "  array([73553.81889193])),\n",
       " (array([7.69025148, 2.81017694, 7.48039875, 7.10897734, 7.33196814,\n",
       "         6.50889107, 4.53468652, 6.53750297]),\n",
       "  array([7.66277899, 2.50014193, 7.54219935, 7.10236787, 7.32217783,\n",
       "         6.45640536, 4.55223879, 6.53784903]),\n",
       "  array([77566.59143291]),\n",
       "  array([73553.81889193])),\n",
       " (array([6.06170208, 2.87496314, 6.90281982, 2.70510471, 7.12808567,\n",
       "         6.70217093, 3.84531715, 3.59228077]),\n",
       "  array([6.02908693, 2.50034578, 6.9854691 , 2.70532951, 7.11357809,\n",
       "         6.63909737, 3.86743006, 3.59457598]),\n",
       "  array([77536.43766143]),\n",
       "  array([72725.73585299])),\n",
       " (array([6.06170208, 2.87496314, 6.90281982, 2.70510471, 7.12808567,\n",
       "         6.70217093, 3.84531715, 3.59228077]),\n",
       "  array([6.02908693, 2.50034578, 6.9854691 , 2.70532951, 7.11357809,\n",
       "         6.63909737, 3.86743006, 3.59457598]),\n",
       "  array([77536.43766143]),\n",
       "  array([72725.73585299])),\n",
       " (array([4.27708762, 4.11694671, 5.97936026, 7.57877923, 5.32415722,\n",
       "         7.90499279, 6.21599661, 5.62194636]),\n",
       "  array([4.15647467, 2.50040924, 6.36240666, 7.54028077, 5.27854047,\n",
       "         7.68299347, 6.29358925, 5.60844755]),\n",
       "  array([77518.29885058]),\n",
       "  array([58515.93787097])),\n",
       " (array([9.25067508, 3.96535082, 6.35253056, 7.82715472, 7.14608988,\n",
       "         4.61303537, 3.0952779 , 3.68570653]),\n",
       "  array([9.11807496, 2.50097351, 6.6961807 , 7.79061097, 7.07535637,\n",
       "         4.31546944, 3.17590308, 3.69003864]),\n",
       "  array([77505.19115906]),\n",
       "  array([60116.86067493])),\n",
       " (array([7.83616152, 4.12446818, 8.26146515, 7.8197602 , 2.56544452,\n",
       "         9.52279921, 6.45425932, 4.03578958]),\n",
       "  array([7.68660329, 2.50053863, 8.54160659, 7.77540492, 2.51828605,\n",
       "         9.28683399, 6.56177822, 4.01286953]),\n",
       "  array([77461.87551889]),\n",
       "  array([59318.15330447])),\n",
       " (array([7.83616152, 4.12446818, 8.26146515, 7.8197602 , 2.56544452,\n",
       "         9.52279921, 6.45425932, 4.03578958]),\n",
       "  array([7.68660329, 2.50053863, 8.54160659, 7.77540492, 2.51828605,\n",
       "         9.28683399, 6.56177822, 4.01286953]),\n",
       "  array([77461.87551889]),\n",
       "  array([59318.15330447])),\n",
       " (array([7.83616152, 4.12446818, 8.26146515, 7.8197602 , 2.56544452,\n",
       "         9.52279921, 6.45425932, 4.03578958]),\n",
       "  array([7.68660329, 2.50053863, 8.54160659, 7.77540492, 2.51828605,\n",
       "         9.28683399, 6.56177822, 4.01286953]),\n",
       "  array([77461.87551889]),\n",
       "  array([59318.15330447])),\n",
       " (array([3.42529972, 3.12091281, 6.22450424, 3.86772238, 2.05499433,\n",
       "         5.28858019, 7.22884385, 3.77197677]),\n",
       "  array([3.42529972, 3.12091281, 6.22450424, 3.86772238, 2.05499433,\n",
       "         5.28858019, 7.22884385, 3.77197677]),\n",
       "  array([77040.73649469]),\n",
       "  array([77040.73649469])),\n",
       " (array([3.42529972, 3.12091281, 6.22450424, 3.86772238, 2.05499433,\n",
       "         5.28858019, 7.22884385, 3.77197677]),\n",
       "  array([3.42529972, 3.12091281, 6.22450424, 3.86772238, 2.05499433,\n",
       "         5.28858019, 7.22884385, 3.77197677]),\n",
       "  array([77040.73649469]),\n",
       "  array([77040.73649469])),\n",
       " (array([3.42529972, 3.12091281, 6.22450424, 3.86772238, 2.05499433,\n",
       "         5.28858019, 7.22884385, 3.77197677]),\n",
       "  array([3.42529972, 3.12091281, 6.22450424, 3.86772238, 2.05499433,\n",
       "         5.28858019, 7.22884385, 3.77197677]),\n",
       "  array([77040.73649469]),\n",
       "  array([77040.73649469])),\n",
       " (array([3.38506849, 3.75294058, 9.5478579 , 2.41258871, 4.68348589,\n",
       "         4.7158803 , 3.87426201, 6.65679341]),\n",
       "  array([3.38506849, 3.75294058, 9.5478579 , 2.41258871, 4.68348589,\n",
       "         4.7158803 , 3.87426201, 6.65679341]),\n",
       "  array([76954.71047766]),\n",
       "  array([76954.71047766])),\n",
       " (array([7.74386775, 4.06369632, 7.97899711, 9.64484403, 8.47690503,\n",
       "         7.27085673, 4.46140229, 6.17626983]),\n",
       "  array([7.60105443, 2.50115209, 8.26679681, 9.58331308, 8.42006882,\n",
       "         7.01065153, 4.55656417, 6.18323364]),\n",
       "  array([76845.58820782]),\n",
       "  array([58826.04635307])),\n",
       " (array([8.44049955, 2.1746643 , 5.92928775, 4.05607782, 8.02181382,\n",
       "         7.98377955, 9.71931208, 2.91415316]),\n",
       "  array([8.44049955, 2.1746643 , 5.92928775, 4.05607782, 8.02181382,\n",
       "         7.98377955, 9.71931208, 2.91415316]),\n",
       "  array([76711.30682215]),\n",
       "  array([76711.30682215])),\n",
       " (array([3.44278251, 2.09204241, 3.67034471, 5.5405317 , 3.84293424,\n",
       "         8.57451087, 9.26924851, 2.9502659 ]),\n",
       "  array([3.44278251, 2.09204241, 3.67034471, 5.5405317 , 3.84293424,\n",
       "         8.57451087, 9.26924851, 2.9502659 ]),\n",
       "  array([76347.89484793]),\n",
       "  array([76347.89484793])),\n",
       " (array([3.44278251, 2.09204241, 3.67034471, 5.5405317 , 3.84293424,\n",
       "         8.57451087, 9.26924851, 2.9502659 ]),\n",
       "  array([3.44278251, 2.09204241, 3.67034471, 5.5405317 , 3.84293424,\n",
       "         8.57451087, 9.26924851, 2.9502659 ]),\n",
       "  array([76347.89484793]),\n",
       "  array([76347.89484793])),\n",
       " (array([3.47162806, 3.8712053 , 4.81450869, 7.01926862, 4.67299764,\n",
       "         6.82779323, 4.26650141, 3.42291838]),\n",
       "  array([3.37384521, 2.50093669, 5.18416925, 6.99318825, 4.62433765,\n",
       "         6.61225641, 4.34093368, 3.41363071]),\n",
       "  array([76001.0797121]),\n",
       "  array([59481.63868677])),\n",
       " (array([3.47162806, 3.8712053 , 4.81450869, 7.01926862, 4.67299764,\n",
       "         6.82779323, 4.26650141, 3.42291838]),\n",
       "  array([3.37384521, 2.50093669, 5.18416925, 6.99318825, 4.62433765,\n",
       "         6.61225641, 4.34093368, 3.41363071]),\n",
       "  array([76001.0797121]),\n",
       "  array([59481.63868677])),\n",
       " (array([8.60608982, 3.68830836, 7.21414797, 6.69336848, 4.97587656,\n",
       "         9.16413346, 8.72876187, 7.56794622]),\n",
       "  array([8.50271414, 2.50081071, 7.44483387, 6.67206426, 4.95196328,\n",
       "         9.02398316, 8.78252976, 7.55368131]),\n",
       "  array([75348.31019911]),\n",
       "  array([61565.73731706])),\n",
       " (array([8.76928857, 2.62834603, 6.056928  , 3.85091014, 8.63540793,\n",
       "         6.21728513, 8.91450645, 9.11925987]),\n",
       "  array([8.75878349, 2.50030961, 6.08619488, 3.85075649, 8.63215529,\n",
       "         6.20038259, 8.91775257, 9.11919723]),\n",
       "  array([75283.79397261]),\n",
       "  array([73584.81342595])),\n",
       " (array([8.76928857, 2.62834603, 6.056928  , 3.85091014, 8.63540793,\n",
       "         6.21728513, 8.91450645, 9.11925987]),\n",
       "  array([8.75878349, 2.50030961, 6.08619488, 3.85075649, 8.63215529,\n",
       "         6.20038259, 8.91775257, 9.11919723]),\n",
       "  array([75283.79397261]),\n",
       "  array([73584.81342595])),\n",
       " (array([8.76928857, 2.62834603, 6.056928  , 3.85091014, 8.63540793,\n",
       "         6.21728513, 8.91450645, 9.11925987]),\n",
       "  array([8.75878349, 2.50030961, 6.08619488, 3.85075649, 8.63215529,\n",
       "         6.20038259, 8.91775257, 9.11919723]),\n",
       "  array([75283.79397261]),\n",
       "  array([73584.81342595])),\n",
       " (array([3.21984115, 5.39741914, 3.06195252, 3.71725886, 3.17636821,\n",
       "         6.49714444, 4.97751651, 3.937595  ]),\n",
       "  array([3.03674118, 2.50114166, 4.06161644, 3.72499718, 3.08440253,\n",
       "         6.05916178, 5.09322235, 3.87730039]),\n",
       "  array([75018.97540322]),\n",
       "  array([43680.74102663])),\n",
       " (array([4.73444547, 4.55713543, 4.76768044, 3.43126218, 6.18119505,\n",
       "         7.97143628, 6.97046524, 6.40215195]),\n",
       "  array([4.58418915, 2.50048681, 5.33481887, 3.43348264, 6.13000496,\n",
       "         7.72655738, 7.04947791, 6.38425255]),\n",
       "  array([74743.13982339]),\n",
       "  array([51791.4423437])),\n",
       " (array([7.73957652, 5.27381196, 4.09706971, 7.71272833, 8.64466748,\n",
       "         5.33383564, 7.07827247, 8.3562118 ]),\n",
       "  array([7.53584592, 2.50023646, 4.92516517, 7.64836211, 8.55567279,\n",
       "         4.9353844 , 7.12989014, 8.33752625]),\n",
       "  array([74196.28999845]),\n",
       "  array([44337.97001957])),\n",
       " (array([8.56216044, 4.33776831, 7.93039701, 4.37255955, 9.41797969,\n",
       "         8.24600758, 2.72828151, 6.3260847 ]),\n",
       "  array([8.3740127 , 2.50073193, 8.27868371, 4.34985358, 9.35672957,\n",
       "         7.93902184, 2.87419412, 6.34320808]),\n",
       "  array([73864.27040014]),\n",
       "  array([54330.92518972])),\n",
       " (array([7.91940831, 5.75010687, 4.99891093, 8.70989058, 9.0463968 ,\n",
       "         6.72622391, 6.36021882, 9.53906911]),\n",
       "  array([7.66075245, 2.50069649, 5.89448827, 8.59548572, 8.96526736,\n",
       "         6.28447347, 6.46681529, 9.5121552 ]),\n",
       "  array([73813.92491788]),\n",
       "  array([41677.91626755])),\n",
       " (array([8.620305  , 6.52387304, 3.88667836, 4.19059542, 8.64203901,\n",
       "         6.0080067 , 6.58945111, 9.07213468]),\n",
       "  array([8.2988447 , 2.50065735, 5.25747142, 4.18335692, 8.53224468,\n",
       "         5.44966303, 6.65618638, 9.01797299]),\n",
       "  array([73797.40611016]),\n",
       "  array([36424.78214145])),\n",
       " (array([8.620305  , 6.52387304, 3.88667836, 4.19059542, 8.64203901,\n",
       "         6.0080067 , 6.58945111, 9.07213468]),\n",
       "  array([8.2988447 , 2.50065735, 5.25747142, 4.18335692, 8.53224468,\n",
       "         5.44966303, 6.65618638, 9.01797299]),\n",
       "  array([73797.40611016]),\n",
       "  array([36424.78214145])),\n",
       " (array([8.620305  , 6.52387304, 3.88667836, 4.19059542, 8.64203901,\n",
       "         6.0080067 , 6.58945111, 9.07213468]),\n",
       "  array([8.2988447 , 2.50065735, 5.25747142, 4.18335692, 8.53224468,\n",
       "         5.44966303, 6.65618638, 9.01797299]),\n",
       "  array([73797.40611016]),\n",
       "  array([36424.78214145])),\n",
       " (array([3.29835214, 3.93847072, 5.76595876, 8.42154026, 8.73202246,\n",
       "         8.79435178, 4.57508597, 9.83259606]),\n",
       "  array([3.19098009, 2.50051314, 6.10624844, 8.37599599, 8.71175908,\n",
       "         8.61673394, 4.66307057, 9.82781261]),\n",
       "  array([73784.60493494]),\n",
       "  array([57190.51116966])),\n",
       " (array([2.59143951, 4.29600963, 9.92058926, 7.27019206, 7.07648428,\n",
       "         9.88620264, 5.32217423, 2.8871521 ]),\n",
       "  array([ 2.50006705,  3.24765356, 10.0750888 ,  7.23582834,  7.03389869,\n",
       "          9.73757635,  5.39226952,  2.89491508]),\n",
       "  array([73624.43270559]),\n",
       "  array([62166.0936111])),\n",
       " (array([3.51324278, 3.07721551, 6.85920372, 6.88783709, 9.21928215,\n",
       "         6.05656858, 5.77688879, 2.11950605]),\n",
       "  array([3.51324278, 3.07721551, 6.85920372, 6.88783709, 9.21928215,\n",
       "         6.05656858, 5.77688879, 2.11950605]),\n",
       "  array([73219.8737354]),\n",
       "  array([73219.8737354])),\n",
       " (array([6.18697757, 6.56882086, 5.81054738, 4.11732198, 8.37180208,\n",
       "         9.82121527, 4.39598059, 8.38180369]),\n",
       "  array([5.81653399, 2.50043775, 6.9145374 , 4.07390172, 8.31132818,\n",
       "         9.38436951, 4.6971382 , 8.34205251]),\n",
       "  array([73133.91439825]),\n",
       "  array([39240.30250222])),\n",
       " (array([6.18697757, 6.56882086, 5.81054738, 4.11732198, 8.37180208,\n",
       "         9.82121527, 4.39598059, 8.38180369]),\n",
       "  array([5.81653399, 2.50043775, 6.9145374 , 4.07390172, 8.31132818,\n",
       "         9.38436951, 4.6971382 , 8.34205251]),\n",
       "  array([73133.91439825]),\n",
       "  array([39240.30250222])),\n",
       " (array([6.18697757, 6.56882086, 5.81054738, 4.11732198, 8.37180208,\n",
       "         9.82121527, 4.39598059, 8.38180369]),\n",
       "  array([5.81653399, 2.50043775, 6.9145374 , 4.07390172, 8.31132818,\n",
       "         9.38436951, 4.6971382 , 8.34205251]),\n",
       "  array([73133.91439825]),\n",
       "  array([39240.30250222])),\n",
       " (array([7.80140724, 2.62842748, 5.54328779, 9.13336153, 7.01419669,\n",
       "         5.73058897, 4.2462284 , 6.93044481]),\n",
       "  array([7.79091898, 2.50056969, 5.57366675, 9.12978068, 7.01033335,\n",
       "         5.70911804, 4.25315685, 6.93010543]),\n",
       "  array([73105.28787059]),\n",
       "  array([71446.04961701])),\n",
       " (array([7.80140724, 2.62842748, 5.54328779, 9.13336153, 7.01419669,\n",
       "         5.73058897, 4.2462284 , 6.93044481]),\n",
       "  array([7.79091898, 2.50056969, 5.57366675, 9.12978068, 7.01033335,\n",
       "         5.70911804, 4.25315685, 6.93010543]),\n",
       "  array([73105.28787059]),\n",
       "  array([71446.04961701])),\n",
       " (array([9.22545751, 3.26607377, 8.6440655 , 9.16676316, 4.04581057,\n",
       "         9.74295102, 4.85377851, 8.01883358]),\n",
       "  array([9.15046639, 2.50064684, 8.76345582, 9.13993516, 4.03413992,\n",
       "         9.6273425 , 4.91529838, 8.00820475]),\n",
       "  array([72875.3046626]),\n",
       "  array([63947.86911199])),\n",
       " (array([7.06647414, 2.09162001, 2.58717138, 7.25293221, 4.98726764,\n",
       "         4.46944891, 4.64931443, 8.29512877]),\n",
       "  array([7.06647414, 2.09162001, 2.58717138, 7.25293221, 4.98726764,\n",
       "         4.46944891, 4.64931443, 8.29512877]),\n",
       "  array([72690.09320826]),\n",
       "  array([72690.09320826])),\n",
       " (array([8.73286359, 2.99412554, 8.71650172, 5.39791854, 9.41658602,\n",
       "         9.58566976, 4.35316024, 4.88773315]),\n",
       "  array([8.6828641 , 2.50094283, 8.79370624, 5.38962954, 9.39910275,\n",
       "         9.51523977, 4.39186969, 4.89456629]),\n",
       "  array([72643.81225492]),\n",
       "  array([66893.50596097])),\n",
       " (array([6.27364679, 3.25691991, 5.53904012, 4.37568764, 6.32528265,\n",
       "         7.43092455, 3.56693159, 9.59640105]),\n",
       "  array([6.21068804, 2.50075104, 5.72679977, 4.37082007, 6.31548088,\n",
       "         7.31441212, 3.61531123, 9.58854767]),\n",
       "  array([72534.06517759]),\n",
       "  array([63337.89400715])),\n",
       " (array([3.05074101, 3.76269683, 3.68850081, 7.14244229, 9.71011984,\n",
       "         7.10126391, 9.5367193 , 3.80073645]),\n",
       "  array([2.97428316, 2.50103601, 4.04534168, 7.12155259, 9.6553422 ,\n",
       "         6.98016349, 9.5564438 , 3.81266731]),\n",
       "  array([72202.79328168]),\n",
       "  array([56722.98247999])),\n",
       " (array([7.64918917, 2.89758583, 7.32706996, 4.79547298, 5.36945525,\n",
       "         9.89016881, 4.4248102 , 5.38032035]),\n",
       "  array([7.61194163, 2.50096885, 7.40297655, 4.79143355, 5.36009426,\n",
       "         9.83522697, 4.45660878, 5.37894365]),\n",
       "  array([72110.67916247]),\n",
       "  array([67451.08429818])),\n",
       " (array([7.64918917, 2.89758583, 7.32706996, 4.79547298, 5.36945525,\n",
       "         9.89016881, 4.4248102 , 5.38032035]),\n",
       "  array([7.61194163, 2.50096885, 7.40297655, 4.79143355, 5.36009426,\n",
       "         9.83522697, 4.45660878, 5.37894365]),\n",
       "  array([72110.67916247]),\n",
       "  array([67451.08429818])),\n",
       " (array([7.64918917, 2.89758583, 7.32706996, 4.79547298, 5.36945525,\n",
       "         9.89016881, 4.4248102 , 5.38032035]),\n",
       "  array([7.61194163, 2.50096885, 7.40297655, 4.79143355, 5.36009426,\n",
       "         9.83522697, 4.45660878, 5.37894365]),\n",
       "  array([72110.67916247]),\n",
       "  array([67451.08429818])),\n",
       " (array([5.85864825, 4.2843192 , 6.14918803, 6.69545209, 5.19060212,\n",
       "         9.4347719 , 3.21813603, 3.40114842]),\n",
       "  array([5.7025641 , 2.50099281, 6.55748854, 6.65586859, 5.13266552,\n",
       "         9.17524245, 3.37063917, 3.39342084]),\n",
       "  array([72033.53855044]),\n",
       "  array([53314.72121675])),\n",
       " (array([5.85864825, 4.2843192 , 6.14918803, 6.69545209, 5.19060212,\n",
       "         9.4347719 , 3.21813603, 3.40114842]),\n",
       "  array([5.7025641 , 2.50099281, 6.55748854, 6.65586859, 5.13266552,\n",
       "         9.17524245, 3.37063917, 3.39342084]),\n",
       "  array([72033.53855044]),\n",
       "  array([53314.72121675])),\n",
       " (array([9.98909637, 3.78430854, 3.97169146, 6.37462202, 6.25493522,\n",
       "         4.41458679, 5.26680229, 8.00511753]),\n",
       "  array([9.88472421, 2.50110065, 4.34326224, 6.3601863 , 6.21836978,\n",
       "         4.19177182, 5.3136753 , 7.99007719]),\n",
       "  array([71851.21845597]),\n",
       "  array([56471.51329565])),\n",
       " (array([7.06856866, 2.21573269, 6.34825617, 7.88644084, 7.55687063,\n",
       "         9.58805763, 3.48553571, 3.46890728]),\n",
       "  array([7.06856866, 2.21573269, 6.34825617, 7.88644084, 7.55687063,\n",
       "         9.58805763, 3.48553571, 3.46890728]),\n",
       "  array([71667.30592196]),\n",
       "  array([71667.30592196])),\n",
       " (array([9.7911429 , 2.02615873, 4.52231431, 3.79395457, 6.29207474,\n",
       "         8.47450088, 6.39128321, 2.82500429]),\n",
       "  array([9.7911429 , 2.02615873, 4.52231431, 3.79395457, 6.29207474,\n",
       "         8.47450088, 6.39128321, 2.82500429]),\n",
       "  array([71448.21420179]),\n",
       "  array([71448.21420179])),\n",
       " (array([8.35167157, 2.53638853, 3.62191849, 5.94652202, 3.26035179,\n",
       "         5.44623108, 7.99273296, 3.63119396]),\n",
       "  array([8.34903837, 2.50056089, 3.63197699, 5.94633776, 3.25907482,\n",
       "         5.44100432, 7.99381283, 3.63077881]),\n",
       "  array([71354.70670069]),\n",
       "  array([70880.64336431])),\n",
       " (array([4.98997542, 5.41873414, 3.61500436, 6.05701488, 8.23160727,\n",
       "         7.29218542, 3.97855472, 9.33913974]),\n",
       "  array([4.77970352, 2.50023216, 4.55461747, 6.00753589, 8.18412828,\n",
       "         6.89919191, 4.13230351, 9.30693383]),\n",
       "  array([70969.79125972]),\n",
       "  array([41513.2146417])),\n",
       " (array([4.98997542, 5.41873414, 3.61500436, 6.05701488, 8.23160727,\n",
       "         7.29218542, 3.97855472, 9.33913974]),\n",
       "  array([4.77970352, 2.50023216, 4.55461747, 6.00753589, 8.18412828,\n",
       "         6.89919191, 4.13230351, 9.30693383]),\n",
       "  array([70969.79125972]),\n",
       "  array([41513.2146417])),\n",
       " (array([4.20966833, 4.82755058, 8.33112372, 6.05386772, 6.45425962,\n",
       "         7.42645223, 9.66165679, 9.32013025]),\n",
       "  array([4.12457293, 3.70307509, 8.55875774, 6.03085477, 6.43021108,\n",
       "         7.28248928, 9.67803401, 9.30537712]),\n",
       "  array([70422.04950154]),\n",
       "  array([58138.74385741])),\n",
       " (array([4.20966833, 4.82755058, 8.33112372, 6.05386772, 6.45425962,\n",
       "         7.42645223, 9.66165679, 9.32013025]),\n",
       "  array([4.12457293, 3.70307509, 8.55875774, 6.03085477, 6.43021108,\n",
       "         7.28248928, 9.67803401, 9.30537712]),\n",
       "  array([70422.04950154]),\n",
       "  array([58138.74385741])),\n",
       " (array([5.109143  , 5.87968232, 2.62457319, 4.73146964, 4.27903775,\n",
       "         8.8700357 , 8.53360342, 4.26528994]),\n",
       "  array([4.90039648, 2.50066961, 3.81896926, 4.72933391, 4.18034433,\n",
       "         8.61724611, 8.62636452, 4.1905141 ]),\n",
       "  array([70083.90528667]),\n",
       "  array([38017.85289092])),\n",
       " (array([9.64967842, 5.9867215 , 3.45196606, 3.87756789, 6.47205822,\n",
       "         6.1415491 , 2.61811839, 4.86949291]),\n",
       "  array([9.33061182, 2.50098062, 4.6917529 , 3.88559308, 6.32758734,\n",
       "         5.48915219, 2.84422606, 4.82802055]),\n",
       "  array([69651.47489208]),\n",
       "  array([37848.1344239])),\n",
       " (array([4.48406123, 2.84138945, 6.15259486, 2.40760362, 7.76871409,\n",
       "         9.821738  , 6.55722958, 9.38768387]),\n",
       "  array([4.48406123, 2.84138945, 6.15259486, 2.40760362, 7.76871409,\n",
       "         9.821738  , 6.55722958, 9.38768387]),\n",
       "  array([69492.16688601]),\n",
       "  array([69492.16688601])),\n",
       " (array([5.0058681 , 6.10893665, 4.29003155, 4.94664391, 8.75459312,\n",
       "         8.26696262, 8.48254088, 5.12644021]),\n",
       "  array([4.78535448, 2.8720593 , 5.2992319 , 4.91811894, 8.62405139,\n",
       "         8.00205224, 8.53981612, 5.12535542]),\n",
       "  array([69418.25835625]),\n",
       "  array([39828.71859378])),\n",
       " (array([5.0058681 , 6.10893665, 4.29003155, 4.94664391, 8.75459312,\n",
       "         8.26696262, 8.48254088, 5.12644021]),\n",
       "  array([4.78543803, 2.87320596, 5.29895017, 4.91812696, 8.62409067,\n",
       "         8.00217472, 8.53977887, 5.12534893]),\n",
       "  array([69404.0648039]),\n",
       "  array([39828.71859378])),\n",
       " (array([5.0058681 , 6.10893665, 4.29003155, 4.94664391, 8.75459312,\n",
       "         8.26696262, 8.48254088, 5.12644021]),\n",
       "  array([4.78552155, 2.87435239, 5.29866846, 4.91813498, 8.62412995,\n",
       "         8.00229716, 8.53974163, 5.12534245]),\n",
       "  array([69389.8767355]),\n",
       "  array([39828.71859378])),\n",
       " (array([6.51327434, 3.49569823, 8.17139805, 2.00121097, 8.00449541,\n",
       "         7.89619011, 6.9767483 , 8.15783429]),\n",
       "  array([6.51327434, 3.49569823, 8.17139805, 2.00121097, 8.00449541,\n",
       "         7.89619011, 6.9767483 , 8.15783429]),\n",
       "  array([67923.80390554]),\n",
       "  array([67923.80390554])),\n",
       " (array([5.74516326, 2.52413459, 4.40026463, 4.53536448, 5.00620419,\n",
       "         8.11704295, 2.55580086, 5.6120337 ]),\n",
       "  array([5.74327023, 2.50078248, 4.40649582, 4.53525649, 5.00569682,\n",
       "         8.11354979, 2.55761813, 5.61186353]),\n",
       "  array([67501.48045042]),\n",
       "  array([67214.05487995])),\n",
       " (array([5.74516326, 2.52413459, 4.40026463, 4.53536448, 5.00620419,\n",
       "         8.11704295, 2.55580086, 5.6120337 ]),\n",
       "  array([5.74327023, 2.50078248, 4.40649582, 4.53525649, 5.00569682,\n",
       "         8.11354979, 2.55761813, 5.61186353]),\n",
       "  array([67501.48045042]),\n",
       "  array([67214.05487995])),\n",
       " (array([6.41370253, 3.84796082, 6.6787151 , 4.50722332, 2.41903965,\n",
       "         5.59174267, 3.64566932, 3.20541394]),\n",
       "  array([6.41370253, 3.84796082, 6.6787151 , 4.50722332, 2.41903965,\n",
       "         5.59174267, 3.64566932, 3.20541394]),\n",
       "  array([65431.41057217]),\n",
       "  array([65431.41057217])),\n",
       " (array([6.41370253, 3.84796082, 6.6787151 , 4.50722332, 2.41903965,\n",
       "         5.59174267, 3.64566932, 3.20541394]),\n",
       "  array([6.41370253, 3.84796082, 6.6787151 , 4.50722332, 2.41903965,\n",
       "         5.59174267, 3.64566932, 3.20541394]),\n",
       "  array([65431.41057217]),\n",
       "  array([65431.41057217])),\n",
       " (array([6.41370253, 3.84796082, 6.6787151 , 4.50722332, 2.41903965,\n",
       "         5.59174267, 3.64566932, 3.20541394]),\n",
       "  array([6.41370253, 3.84796082, 6.6787151 , 4.50722332, 2.41903965,\n",
       "         5.59174267, 3.64566932, 3.20541394]),\n",
       "  array([65431.41057217]),\n",
       "  array([65431.41057217])),\n",
       " (array([4.42431165, 2.29500017, 2.62214858, 6.27300698, 7.97761983,\n",
       "         8.26637821, 4.20514328, 5.36314825]),\n",
       "  array([4.42431165, 2.29500017, 2.62214858, 6.27300698, 7.97761983,\n",
       "         8.26637821, 4.20514328, 5.36314825]),\n",
       "  array([65425.48498542]),\n",
       "  array([65425.48498542])),\n",
       " (array([2.0492438 , 3.76322981, 5.37982854, 5.86245733, 4.71079861,\n",
       "         5.4551199 , 6.22584348, 9.5382352 ]),\n",
       "  array([2.0492438 , 3.76322981, 5.37982854, 5.86245733, 4.71079861,\n",
       "         5.4551199 , 6.22584348, 9.5382352 ]),\n",
       "  array([65400.96272759]),\n",
       "  array([65400.96272759])),\n",
       " (array([5.77545084, 2.56032368, 2.84687668, 5.7254832 , 8.17997311,\n",
       "         7.81889402, 6.69193553, 5.6801515 ]),\n",
       "  array([5.77129165, 2.50092301, 2.8642997 , 5.72506868, 8.17825028,\n",
       "         7.81258796, 6.6945951 , 5.68025489]),\n",
       "  array([64935.47018887]),\n",
       "  array([64199.67835436])),\n",
       " (array([7.59534288, 4.98718601, 2.62978363, 5.69085127, 8.31056625,\n",
       "         9.62661298, 9.06865306, 9.8931685 ]),\n",
       "  array([7.42088402, 2.50029842, 3.43412351, 5.67147445, 8.28974483,\n",
       "         9.51058855, 9.14744331, 9.8591164 ]),\n",
       "  array([64748.69682456]),\n",
       "  array([40713.13116014])),\n",
       " (array([9.58208102, 3.06765062, 6.30107851, 9.56138391, 2.079334  ,\n",
       "         9.88368351, 7.93913278, 4.99526955]),\n",
       "  array([9.58208102, 3.06765062, 6.30107851, 9.56138391, 2.079334  ,\n",
       "         9.88368351, 7.93913278, 4.99526955]),\n",
       "  array([64139.50809944]),\n",
       "  array([64139.50809944])),\n",
       " (array([9.58208102, 3.06765062, 6.30107851, 9.56138391, 2.079334  ,\n",
       "         9.88368351, 7.93913278, 4.99526955]),\n",
       "  array([9.58208102, 3.06765062, 6.30107851, 9.56138391, 2.079334  ,\n",
       "         9.88368351, 7.93913278, 4.99526955]),\n",
       "  array([64139.50809944]),\n",
       "  array([64139.50809944])),\n",
       " (array([9.58208102, 3.06765062, 6.30107851, 9.56138391, 2.079334  ,\n",
       "         9.88368351, 7.93913278, 4.99526955]),\n",
       "  array([9.58208102, 3.06765062, 6.30107851, 9.56138391, 2.079334  ,\n",
       "         9.88368351, 7.93913278, 4.99526955]),\n",
       "  array([64139.50809944]),\n",
       "  array([64139.50809944])),\n",
       " (array([6.26869478, 2.7793247 , 2.85418812, 9.87090656, 8.23408446,\n",
       "         4.93358931, 2.15131749, 8.82074611]),\n",
       "  array([6.26869478, 2.7793247 , 2.85418812, 9.87090656, 8.23408446,\n",
       "         4.93358931, 2.15131749, 8.82074611]),\n",
       "  array([62247.78215649]),\n",
       "  array([62247.78215649])),\n",
       " (array([6.26869478, 2.7793247 , 2.85418812, 9.87090656, 8.23408446,\n",
       "         4.93358931, 2.15131749, 8.82074611]),\n",
       "  array([6.26869478, 2.7793247 , 2.85418812, 9.87090656, 8.23408446,\n",
       "         4.93358931, 2.15131749, 8.82074611]),\n",
       "  array([62247.78215649]),\n",
       "  array([62247.78215649])),\n",
       " (array([6.70066522, 3.04066453, 3.44555526, 2.19836695, 3.57994109,\n",
       "         6.26423593, 4.54553226, 7.60479519]),\n",
       "  array([6.70066522, 3.04066453, 3.44555526, 2.19836695, 3.57994109,\n",
       "         6.26423593, 4.54553226, 7.60479519]),\n",
       "  array([62156.25871546]),\n",
       "  array([62156.25871546])),\n",
       " (array([6.70066522, 3.04066453, 3.44555526, 2.19836695, 3.57994109,\n",
       "         6.26423593, 4.54553226, 7.60479519]),\n",
       "  array([6.70066522, 3.04066453, 3.44555526, 2.19836695, 3.57994109,\n",
       "         6.26423593, 4.54553226, 7.60479519]),\n",
       "  array([62156.25871546]),\n",
       "  array([62156.25871546])),\n",
       " (array([3.0885825 , 7.34552638, 5.19000697, 2.65042012, 8.70100458,\n",
       "         8.68577093, 7.85250398, 8.18927875]),\n",
       "  array([2.87622199, 4.05391678, 6.35500247, 2.66367772, 8.6274635 ,\n",
       "         8.47539558, 7.87078521, 8.13509009]),\n",
       "  array([60558.93500346]),\n",
       "  array([36754.46835563])),\n",
       " (array([8.07467226, 3.47925257, 5.06175521, 2.20120157, 8.43040333,\n",
       "         6.00335154, 2.08096464, 3.39491605]),\n",
       "  array([8.07467226, 3.47925257, 5.06175521, 2.20120157, 8.43040333,\n",
       "         6.00335154, 2.08096464, 3.39491605]),\n",
       "  array([59236.75464846]),\n",
       "  array([59236.75464846])),\n",
       " (array([2.12717718, 4.24935594, 4.83282894, 9.48940368, 6.69310519,\n",
       "         4.95351523, 4.76269905, 3.49531252]),\n",
       "  array([2.12717718, 4.24935594, 4.83282894, 9.48940368, 6.69310519,\n",
       "         4.95351523, 4.76269905, 3.49531252]),\n",
       "  array([58366.38822245]),\n",
       "  array([58366.38822245])),\n",
       " (array([2.12717718, 4.24935594, 4.83282894, 9.48940368, 6.69310519,\n",
       "         4.95351523, 4.76269905, 3.49531252]),\n",
       "  array([2.12717718, 4.24935594, 4.83282894, 9.48940368, 6.69310519,\n",
       "         4.95351523, 4.76269905, 3.49531252]),\n",
       "  array([58366.38822245]),\n",
       "  array([58366.38822245])),\n",
       " (array([8.83000503, 3.1276826 , 3.02323138, 9.23555348, 2.24817777,\n",
       "         7.03314596, 8.09570781, 9.44711057]),\n",
       "  array([8.83000503, 3.1276826 , 3.02323138, 9.23555348, 2.24817777,\n",
       "         7.03314596, 8.09570781, 9.44711057]),\n",
       "  array([57975.68378887]),\n",
       "  array([57975.68378887])),\n",
       " (array([9.11734161, 4.62170205, 7.94388518, 6.60341554, 2.49021443,\n",
       "         6.55352558, 9.78509528, 8.66810885]),\n",
       "  array([9.11734161, 4.62170205, 7.94388518, 6.60341554, 2.49021443,\n",
       "         6.55352558, 9.78509528, 8.66810885]),\n",
       "  array([57563.49352035]),\n",
       "  array([57563.49352035])),\n",
       " (array([5.26580953, 4.97583277, 9.0757182 , 7.6018415 , 2.07617314,\n",
       "         9.49516943, 9.77873692, 3.43226772]),\n",
       "  array([5.26580953, 4.97583277, 9.0757182 , 7.6018415 , 2.07617314,\n",
       "         9.49516943, 9.77873692, 3.43226772]),\n",
       "  array([56978.07774736]),\n",
       "  array([56978.07774736])),\n",
       " (array([3.45178366, 3.16493323, 3.21300463, 9.45070468, 8.7591459 ,\n",
       "         8.33173528, 2.20600069, 6.42737392]),\n",
       "  array([3.45178366, 3.16493323, 3.21300463, 9.45070468, 8.7591459 ,\n",
       "         8.33173528, 2.20600069, 6.42737392]),\n",
       "  array([56321.8718417]),\n",
       "  array([56321.8718417])),\n",
       " (array([3.45178366, 3.16493323, 3.21300463, 9.45070468, 8.7591459 ,\n",
       "         8.33173528, 2.20600069, 6.42737392]),\n",
       "  array([3.45178366, 3.16493323, 3.21300463, 9.45070468, 8.7591459 ,\n",
       "         8.33173528, 2.20600069, 6.42737392]),\n",
       "  array([56321.8718417]),\n",
       "  array([56321.8718417])),\n",
       " (array([5.14102609, 5.07067598, 7.82167251, 5.88382289, 4.616266  ,\n",
       "         5.83559506, 2.12023149, 2.63866538]),\n",
       "  array([5.14102609, 5.07067598, 7.82167251, 5.88382289, 4.616266  ,\n",
       "         5.83559506, 2.12023149, 2.63866538]),\n",
       "  array([55912.15024953]),\n",
       "  array([55912.15024953])),\n",
       " (array([5.14102609, 5.07067598, 7.82167251, 5.88382289, 4.616266  ,\n",
       "         5.83559506, 2.12023149, 2.63866538]),\n",
       "  array([5.14102609, 5.07067598, 7.82167251, 5.88382289, 4.616266  ,\n",
       "         5.83559506, 2.12023149, 2.63866538]),\n",
       "  array([55912.15024953]),\n",
       "  array([55912.15024953])),\n",
       " (array([2.26868462, 5.67271368, 9.03633636, 2.63628808, 9.05678772,\n",
       "         5.00173664, 2.85754855, 8.3474022 ]),\n",
       "  array([2.26868462, 5.67271368, 9.03633636, 2.63628808, 9.05678772,\n",
       "         5.00173664, 2.85754855, 8.3474022 ]),\n",
       "  array([55857.50408395]),\n",
       "  array([55857.50408395])),\n",
       " (array([6.91978916, 4.53707388, 7.9328357 , 8.30605018, 9.08887307,\n",
       "         6.69618702, 2.00585872, 2.81610416]),\n",
       "  array([6.91978916, 4.53707388, 7.9328357 , 8.30605018, 9.08887307,\n",
       "         6.69618702, 2.00585872, 2.81610416]),\n",
       "  array([54833.86356425]),\n",
       "  array([54833.86356425])),\n",
       " (array([4.31666012, 3.86802621, 2.32225016, 2.61348146, 6.03567236,\n",
       "         4.31940999, 5.86434536, 9.52098839]),\n",
       "  array([4.31666012, 3.86802621, 2.32225016, 2.61348146, 6.03567236,\n",
       "         4.31940999, 5.86434536, 9.52098839]),\n",
       "  array([54154.08178909]),\n",
       "  array([54154.08178909])),\n",
       " (array([4.31666012, 3.86802621, 2.32225016, 2.61348146, 6.03567236,\n",
       "         4.31940999, 5.86434536, 9.52098839]),\n",
       "  array([4.31666012, 3.86802621, 2.32225016, 2.61348146, 6.03567236,\n",
       "         4.31940999, 5.86434536, 9.52098839]),\n",
       "  array([54154.08178909]),\n",
       "  array([54154.08178909])),\n",
       " (array([2.77580922, 3.72582298, 2.45069058, 8.23582683, 9.28100114,\n",
       "         6.83650414, 4.17394074, 6.97840703]),\n",
       "  array([2.77580922, 3.72582298, 2.45069058, 8.23582683, 9.28100114,\n",
       "         6.83650414, 4.17394074, 6.97840703]),\n",
       "  array([52221.80936587]),\n",
       "  array([52221.80936587])),\n",
       " (array([4.75209249, 3.86500166, 2.10559135, 4.8232818 , 7.21272293,\n",
       "         6.38729759, 8.33755428, 9.08530604]),\n",
       "  array([4.75209249, 3.86500166, 2.10559135, 4.8232818 , 7.21272293,\n",
       "         6.38729759, 8.33755428, 9.08530604]),\n",
       "  array([51020.46621753]),\n",
       "  array([51020.46621753])),\n",
       " (array([4.75209249, 3.86500166, 2.10559135, 4.8232818 , 7.21272293,\n",
       "         6.38729759, 8.33755428, 9.08530604]),\n",
       "  array([4.75209249, 3.86500166, 2.10559135, 4.8232818 , 7.21272293,\n",
       "         6.38729759, 8.33755428, 9.08530604]),\n",
       "  array([51020.46621753]),\n",
       "  array([51020.46621753])),\n",
       " (array([2.37535311, 6.02267168, 8.37377495, 4.53309991, 7.7243974 ,\n",
       "         6.89612848, 4.43453858, 3.57922737]),\n",
       "  array([2.37535311, 6.02267168, 8.37377495, 4.53309991, 7.7243974 ,\n",
       "         6.89612848, 4.43453858, 3.57922737]),\n",
       "  array([50140.49985484]),\n",
       "  array([50140.49985484])),\n",
       " (array([5.47555738, 4.89731791, 5.30721761, 2.42642505, 5.30376549,\n",
       "         8.10282177, 9.92544991, 8.50215086]),\n",
       "  array([5.47555738, 4.89731791, 5.30721761, 2.42642505, 5.30376549,\n",
       "         8.10282177, 9.92544991, 8.50215086]),\n",
       "  array([50072.33684163]),\n",
       "  array([50072.33684163])),\n",
       " (array([2.08143832, 5.49587179, 6.29274552, 9.61414548, 9.6211931 ,\n",
       "         5.716947  , 7.03471605, 4.12567358]),\n",
       "  array([2.08143832, 5.49587179, 6.29274552, 9.61414548, 9.6211931 ,\n",
       "         5.716947  , 7.03471605, 4.12567358]),\n",
       "  array([49443.8653848]),\n",
       "  array([49443.8653848])),\n",
       " (array([2.08143832, 5.49587179, 6.29274552, 9.61414548, 9.6211931 ,\n",
       "         5.716947  , 7.03471605, 4.12567358]),\n",
       "  array([2.08143832, 5.49587179, 6.29274552, 9.61414548, 9.6211931 ,\n",
       "         5.716947  , 7.03471605, 4.12567358]),\n",
       "  array([49443.8653848]),\n",
       "  array([49443.8653848])),\n",
       " (array([2.08143832, 5.49587179, 6.29274552, 9.61414548, 9.6211931 ,\n",
       "         5.716947  , 7.03471605, 4.12567358]),\n",
       "  array([2.08143832, 5.49587179, 6.29274552, 9.61414548, 9.6211931 ,\n",
       "         5.716947  , 7.03471605, 4.12567358]),\n",
       "  array([49443.8653848]),\n",
       "  array([49443.8653848])),\n",
       " (array([2.08143832, 5.49587179, 6.29274552, 9.61414548, 9.6211931 ,\n",
       "         5.716947  , 7.03471605, 4.12567358]),\n",
       "  array([2.08143832, 5.49587179, 6.29274552, 9.61414548, 9.6211931 ,\n",
       "         5.716947  , 7.03471605, 4.12567358]),\n",
       "  array([49443.8653848]),\n",
       "  array([49443.8653848])),\n",
       " (array([6.25437912, 4.24696162, 3.97600304, 7.53631715, 2.00278013,\n",
       "         7.8963462 , 2.3164338 , 8.83421963]),\n",
       "  array([6.25437912, 4.24696162, 3.97600304, 7.53631715, 2.00278013,\n",
       "         7.8963462 , 2.3164338 , 8.83421963]),\n",
       "  array([48670.73496768]),\n",
       "  array([48670.73496768])),\n",
       " (array([2.47814031, 4.29828807, 2.39608428, 7.11552166, 5.27145786,\n",
       "         8.97655689, 8.30729543, 2.4269276 ]),\n",
       "  array([2.47814031, 4.29828807, 2.39608428, 7.11552166, 5.27145786,\n",
       "         8.97655689, 8.30729543, 2.4269276 ]),\n",
       "  array([48489.5205714]),\n",
       "  array([48489.5205714])),\n",
       " (array([2.47814031, 4.29828807, 2.39608428, 7.11552166, 5.27145786,\n",
       "         8.97655689, 8.30729543, 2.4269276 ]),\n",
       "  array([2.47814031, 4.29828807, 2.39608428, 7.11552166, 5.27145786,\n",
       "         8.97655689, 8.30729543, 2.4269276 ]),\n",
       "  array([48489.5205714]),\n",
       "  array([48489.5205714])),\n",
       " (array([3.57861903, 6.280178  , 8.65911151, 9.68024777, 5.08156352,\n",
       "         7.32347276, 7.9498362 , 2.06146579]),\n",
       "  array([3.57861903, 6.280178  , 8.65911151, 9.68024777, 5.08156352,\n",
       "         7.32347276, 7.9498362 , 2.06146579]),\n",
       "  array([48111.02279279]),\n",
       "  array([48111.02279279])),\n",
       " (array([3.57861903, 6.280178  , 8.65911151, 9.68024777, 5.08156352,\n",
       "         7.32347276, 7.9498362 , 2.06146579]),\n",
       "  array([3.57861903, 6.280178  , 8.65911151, 9.68024777, 5.08156352,\n",
       "         7.32347276, 7.9498362 , 2.06146579]),\n",
       "  array([48111.02279279]),\n",
       "  array([48111.02279279])),\n",
       " (array([2.42158645, 5.36692403, 4.19314939, 9.88923386, 3.3281671 ,\n",
       "         7.72567782, 2.5713273 , 4.58021405]),\n",
       "  array([2.42158645, 5.36692403, 4.19314939, 9.88923386, 3.3281671 ,\n",
       "         7.72567782, 2.5713273 , 4.58021405]),\n",
       "  array([43921.2861092]),\n",
       "  array([43921.2861092])),\n",
       " (array([2.24938549, 7.1355691 , 9.60357587, 6.03064032, 9.55679646,\n",
       "         9.94656893, 5.29311738, 3.4859656 ]),\n",
       "  array([2.24938549, 7.1355691 , 9.60357587, 6.03064032, 9.55679646,\n",
       "         9.94656893, 5.29311738, 3.4859656 ]),\n",
       "  array([42781.92518807]),\n",
       "  array([42781.92518807])),\n",
       " (array([4.63909766, 7.2714982 , 6.86832483, 2.26021714, 3.85604358,\n",
       "         7.69309272, 2.95277771, 3.86600877]),\n",
       "  array([4.63909766, 7.2714982 , 6.86832483, 2.26021714, 3.85604358,\n",
       "         7.69309272, 2.95277771, 3.86600877]),\n",
       "  array([40924.22529014]),\n",
       "  array([40924.22529014])),\n",
       " (array([4.63909766, 7.2714982 , 6.86832483, 2.26021714, 3.85604358,\n",
       "         7.69309272, 2.95277771, 3.86600877]),\n",
       "  array([4.63909766, 7.2714982 , 6.86832483, 2.26021714, 3.85604358,\n",
       "         7.69309272, 2.95277771, 3.86600877]),\n",
       "  array([40924.22529014]),\n",
       "  array([40924.22529014])),\n",
       " (array([4.63909766, 7.2714982 , 6.86832483, 2.26021714, 3.85604358,\n",
       "         7.69309272, 2.95277771, 3.86600877]),\n",
       "  array([4.63909766, 7.2714982 , 6.86832483, 2.26021714, 3.85604358,\n",
       "         7.69309272, 2.95277771, 3.86600877]),\n",
       "  array([40924.22529014]),\n",
       "  array([40924.22529014])),\n",
       " (array([6.31474184, 7.9625008 , 9.62109694, 5.82377057, 6.71586524,\n",
       "         9.89056473, 6.83650778, 5.31607151]),\n",
       "  array([6.31471054, 7.96229158, 9.62114224, 5.82374877, 6.71584865,\n",
       "         9.8905481 , 6.83651392, 5.31605701]),\n",
       "  array([39798.77475111]),\n",
       "  array([39798.29390913])),\n",
       " (array([7.73649831, 6.41277343, 6.98165062, 9.38499875, 7.25833299,\n",
       "         9.01180244, 2.22250342, 2.63210608]),\n",
       "  array([7.73649831, 6.41277343, 6.98165062, 9.38499875, 7.25833299,\n",
       "         9.01180244, 2.22250342, 2.63210608]),\n",
       "  array([39716.28238701]),\n",
       "  array([39716.28238701])),\n",
       " (array([4.97407362, 8.85392438, 9.0420079 , 3.11567614, 3.9913667 ,\n",
       "         9.06772489, 5.74886625, 5.50569836]),\n",
       "  array([4.97405783, 8.85385785, 9.04206675, 3.11567116, 3.99135926,\n",
       "         9.06770881, 5.74886286, 5.50566913]),\n",
       "  array([39351.45507659]),\n",
       "  array([39351.36163836])),\n",
       " (array([4.97407362, 8.85392438, 9.0420079 , 3.11567614, 3.9913667 ,\n",
       "         9.06772489, 5.74886625, 5.50569836]),\n",
       "  array([4.97405783, 8.85385785, 9.04206675, 3.11567116, 3.99135926,\n",
       "         9.06770881, 5.74886286, 5.50566913]),\n",
       "  array([39351.45507659]),\n",
       "  array([39351.36163836])),\n",
       " (array([4.03335766, 7.63764846, 6.75125065, 4.09463841, 9.23440151,\n",
       "         6.63295844, 4.6558113 , 5.67161037]),\n",
       "  array([4.0320016 , 7.62062666, 6.76014853, 4.09412373, 9.23293555,\n",
       "         6.62984053, 4.65561004, 5.6712365 ]),\n",
       "  array([39277.94990784]),\n",
       "  array([39213.01698667])),\n",
       " (array([4.03335766, 7.63764846, 6.75125065, 4.09463841, 9.23440151,\n",
       "         6.63295844, 4.6558113 , 5.67161037]),\n",
       "  array([4.0320016 , 7.62062666, 6.76014853, 4.09412373, 9.23293555,\n",
       "         6.62984053, 4.65561004, 5.6712365 ]),\n",
       "  array([39277.94990784]),\n",
       "  array([39213.01698667])),\n",
       " (array([4.35731951, 7.89332195, 6.7374508 , 3.37760199, 5.12331635,\n",
       "         9.62994404, 6.41174055, 5.39699171]),\n",
       "  array([4.35714341, 7.89124704, 6.73878447, 3.37757878, 5.123225  ,\n",
       "         9.62994125, 6.41175976, 5.39673161]),\n",
       "  array([38483.68246623]),\n",
       "  array([38478.05310028])),\n",
       " (array([5.52565651, 7.8627154 , 7.70078007, 3.22432224, 9.65843035,\n",
       "         8.85661078, 3.97036025, 9.9543257 ]),\n",
       "  array([5.52565651, 7.8627154 , 7.70078007, 3.22432224, 9.65843035,\n",
       "         8.85661078, 3.97036025, 9.9543257 ]),\n",
       "  array([38241.89522611]),\n",
       "  array([38241.89522611])),\n",
       " (array([8.93118239, 8.0127891 , 9.97709212, 8.00819807, 2.91740485,\n",
       "         9.66763027, 4.27111457, 6.41234245]),\n",
       "  array([8.93118239, 8.0127891 , 9.97709212, 8.00819807, 2.91740485,\n",
       "         9.66763027, 4.27111457, 6.41234245]),\n",
       "  array([38083.98579968]),\n",
       "  array([38083.98579968])),\n",
       " (array([4.91825354, 8.84363622, 8.66625149, 2.02358779, 9.74090145,\n",
       "         9.86560545, 7.37689289, 9.83481264]),\n",
       "  array([4.91825354, 8.84363622, 8.66625149, 2.02358779, 9.74090145,\n",
       "         9.86560545, 7.37689289, 9.83481264]),\n",
       "  array([37937.64892269]),\n",
       "  array([37937.64892269])),\n",
       " (array([7.96228433, 8.94982755, 8.14662728, 4.20372935, 6.1152242 ,\n",
       "         7.86171944, 6.43489365, 6.10629442]),\n",
       "  array([7.96228433, 8.94982755, 8.14662728, 4.20372935, 6.1152242 ,\n",
       "         7.86171944, 6.43489365, 6.10629442]),\n",
       "  array([37935.81976833]),\n",
       "  array([37935.81976833])),\n",
       " (array([8.00038394, 8.01040703, 8.39539127, 3.58537272, 3.25838512,\n",
       "         8.3279503 , 8.18537281, 9.91936961]),\n",
       "  array([8.00020937, 8.00900868, 8.39595524, 3.5853498 , 3.25841723,\n",
       "         8.327774  , 8.18529484, 9.91912628]),\n",
       "  array([37860.44581604]),\n",
       "  array([37856.44237771])),\n",
       " (array([8.00038394, 8.01040703, 8.39539127, 3.58537272, 3.25838512,\n",
       "         8.3279503 , 8.18537281, 9.91936961]),\n",
       "  array([8.00020937, 8.00900868, 8.39595524, 3.5853498 , 3.25841723,\n",
       "         8.327774  , 8.18529484, 9.91912628]),\n",
       "  array([37860.44581604]),\n",
       "  array([37856.44237771])),\n",
       " (array([5.25904766, 8.20173937, 7.41872267, 8.21652658, 2.64033946,\n",
       "         8.93704144, 9.65310424, 5.90079695]),\n",
       "  array([5.25903568, 8.20153484, 7.41882727, 8.21649783, 2.64033065,\n",
       "         8.93704104, 9.6530819 , 5.90075993]),\n",
       "  array([37496.91669488]),\n",
       "  array([37496.35977709])),\n",
       " (array([9.37117828, 8.91561452, 9.63227616, 3.66125118, 9.98231288,\n",
       "         9.72152193, 9.9229497 , 7.03697657]),\n",
       "  array([9.37115685, 8.91559058, 9.63229089, 3.66124391, 9.98229796,\n",
       "         9.72156033, 9.92291858, 7.03696799]),\n",
       "  array([37082.08387827]),\n",
       "  array([37082.04345813])),\n",
       " (array([5.55660753, 5.66597905, 2.14178692, 8.16738261, 6.53428476,\n",
       "         7.1771633 , 3.07581495, 2.23260327]),\n",
       "  array([5.55660753, 5.66597905, 2.14178692, 8.16738261, 6.53428476,\n",
       "         7.1771633 , 3.07581495, 2.23260327]),\n",
       "  array([36805.85376187]),\n",
       "  array([36805.85376187])),\n",
       " (array([4.27814356, 8.96585095, 7.57448175, 8.7051576 , 4.56471608,\n",
       "         8.7318882 , 8.79337048, 7.01202137]),\n",
       "  array([4.27814356, 8.96585095, 7.57448175, 8.7051576 , 4.56471608,\n",
       "         8.7318882 , 8.79337048, 7.01202137]),\n",
       "  array([36172.93601571]),\n",
       "  array([36172.93601571])),\n",
       " (array([9.85340823, 9.26563236, 7.95923307, 3.64831335, 9.36963147,\n",
       "         7.99682817, 9.43597667, 6.95061809]),\n",
       "  array([9.85340823, 9.26563236, 7.95923307, 3.64831335, 9.36963147,\n",
       "         7.99682817, 9.43597667, 6.95061809]),\n",
       "  array([36138.82304137]),\n",
       "  array([36138.82304137])),\n",
       " (array([9.85340823, 9.26563236, 7.95923307, 3.64831335, 9.36963147,\n",
       "         7.99682817, 9.43597667, 6.95061809]),\n",
       "  array([9.85340823, 9.26563236, 7.95923307, 3.64831335, 9.36963147,\n",
       "         7.99682817, 9.43597667, 6.95061809]),\n",
       "  array([36138.82304137]),\n",
       "  array([36138.82304137])),\n",
       " (array([5.49215417, 8.26276766, 6.21403859, 8.44036831, 9.6772564 ,\n",
       "         6.78353181, 2.86848029, 5.2141351 ]),\n",
       "  array([5.49213116, 8.26255968, 6.21428262, 8.44030212, 9.67720861,\n",
       "         6.78346164, 2.86848771, 5.21412127]),\n",
       "  array([35955.68279589]),\n",
       "  array([35955.10690946])),\n",
       " (array([5.49215417, 8.26276766, 6.21403859, 8.44036831, 9.6772564 ,\n",
       "         6.78353181, 2.86848029, 5.2141351 ]),\n",
       "  array([5.49213116, 8.26255968, 6.21428262, 8.44030212, 9.67720861,\n",
       "         6.78346164, 2.86848771, 5.21412127]),\n",
       "  array([35955.68279589]),\n",
       "  array([35955.10690946])),\n",
       " (array([5.49215417, 8.26276766, 6.21403859, 8.44036831, 9.6772564 ,\n",
       "         6.78353181, 2.86848029, 5.2141351 ]),\n",
       "  array([5.49213116, 8.26255968, 6.21428262, 8.44030212, 9.67720861,\n",
       "         6.78346164, 2.86848771, 5.21412127]),\n",
       "  array([35955.68279589]),\n",
       "  array([35955.10690946])),\n",
       " (array([2.23961504, 8.3725092 , 5.76464559, 8.49609801, 5.52093922,\n",
       "         8.51519405, 6.79952069, 5.19043906]),\n",
       "  array([2.23961504, 8.3725092 , 5.76464559, 8.49609801, 5.52093922,\n",
       "         8.51519405, 6.79952069, 5.19043906]),\n",
       "  array([35670.99391096]),\n",
       "  array([35670.99391096])),\n",
       " (array([2.23961504, 8.3725092 , 5.76464559, 8.49609801, 5.52093922,\n",
       "         8.51519405, 6.79952069, 5.19043906]),\n",
       "  array([2.23961504, 8.3725092 , 5.76464559, 8.49609801, 5.52093922,\n",
       "         8.51519405, 6.79952069, 5.19043906]),\n",
       "  array([35670.99391096]),\n",
       "  array([35670.99391096])),\n",
       " (array([2.23961504, 8.3725092 , 5.76464559, 8.49609801, 5.52093922,\n",
       "         8.51519405, 6.79952069, 5.19043906]),\n",
       "  array([2.23961504, 8.3725092 , 5.76464559, 8.49609801, 5.52093922,\n",
       "         8.51519405, 6.79952069, 5.19043906]),\n",
       "  array([35670.99391096]),\n",
       "  array([35670.99391096])),\n",
       " (array([7.63168609, 5.96373284, 2.15863472, 3.58381163, 6.85386144,\n",
       "         7.45234988, 8.66903784, 3.46879002]),\n",
       "  array([7.63168609, 5.96373284, 2.15863472, 3.58381163, 6.85386144,\n",
       "         7.45234988, 8.66903784, 3.46879002]),\n",
       "  array([35474.39655556]),\n",
       "  array([35474.39655556])),\n",
       " (array([6.39951632, 9.79564212, 7.35208721, 9.51407639, 6.46764197,\n",
       "         8.22852305, 8.03919005, 9.79319301]),\n",
       "  array([6.39953456, 9.79587122, 7.3522088 , 9.5139997 , 6.46765067,\n",
       "         8.22859748, 8.0391128 , 9.79312224]),\n",
       "  array([35140.0357461]),\n",
       "  array([35139.58532668])),\n",
       " (array([6.39951632, 9.79564212, 7.35208721, 9.51407639, 6.46764197,\n",
       "         8.22852305, 8.03919005, 9.79319301]),\n",
       "  array([6.39953456, 9.79587122, 7.3522088 , 9.5139997 , 6.46765067,\n",
       "         8.22859748, 8.0391128 , 9.79312224]),\n",
       "  array([35140.0357461]),\n",
       "  array([35139.58532668])),\n",
       " (array([2.41785327, 8.26680725, 4.55367652, 4.91451848, 5.77937036,\n",
       "         9.39042502, 2.42309088, 4.50039664]),\n",
       "  array([2.41785327, 8.26680725, 4.55367652, 4.91451848, 5.77937036,\n",
       "         9.39042502, 2.42309088, 4.50039664]),\n",
       "  array([34848.44729995]),\n",
       "  array([34848.44729995])),\n",
       " (array([9.83432547, 6.94863436, 3.83738488, 4.29967216, 8.70712003,\n",
       "         7.72073973, 3.80252696, 6.15572894]),\n",
       "  array([9.83400292, 6.94598521, 3.83953128, 4.29966309, 8.70694159,\n",
       "         7.72046711, 3.80272417, 6.15559903]),\n",
       "  array([34317.50532395]),\n",
       "  array([34307.59540235])),\n",
       " (array([3.55884111, 8.82054754, 5.0221135 , 9.09558674, 9.55597083,\n",
       "         9.22706312, 3.25523373, 5.21691621]),\n",
       "  array([3.55884111, 8.82054754, 5.0221135 , 9.09558674, 9.55597083,\n",
       "         9.22706312, 3.25523373, 5.21691621]),\n",
       "  array([34249.16780787]),\n",
       "  array([34249.16780787])),\n",
       " (array([2.03244791, 8.18813841, 4.71158335, 7.96056465, 9.2849744 ,\n",
       "         7.50539063, 4.96642356, 4.54650204]),\n",
       "  array([2.03244791, 8.18813841, 4.71158335, 7.96056465, 9.2849744 ,\n",
       "         7.50539063, 4.96642356, 4.54650204]),\n",
       "  array([34107.72923143]),\n",
       "  array([34107.72923143])),\n",
       " (array([3.13647961, 8.48256887, 3.92780283, 8.36598977, 3.9629386 ,\n",
       "         9.09679814, 8.10348771, 4.7824802 ]),\n",
       "  array([3.13649289, 8.48250358, 3.92796837, 8.36596527, 3.9629314 ,\n",
       "         9.09684036, 8.10346432, 4.78244658]),\n",
       "  array([33025.95353924]),\n",
       "  array([33025.59400564])),\n",
       " (array([3.13647961, 8.48256887, 3.92780283, 8.36598977, 3.9629386 ,\n",
       "         9.09679814, 8.10348771, 4.7824802 ]),\n",
       "  array([3.13649289, 8.48250358, 3.92796837, 8.36596527, 3.9629314 ,\n",
       "         9.09684036, 8.10346432, 4.78244658]),\n",
       "  array([33025.95353924]),\n",
       "  array([33025.59400564])),\n",
       " (array([4.85018295, 8.39532251, 4.51192896, 6.54405967, 9.2382256 ,\n",
       "         8.89249209, 8.39590231, 9.20570753]),\n",
       "  array([4.85018295, 8.39532251, 4.51192896, 6.54405967, 9.2382256 ,\n",
       "         8.89249209, 8.39590231, 9.20570753]),\n",
       "  array([32974.22691955]),\n",
       "  array([32974.22691955])),\n",
       " (array([4.85018295, 8.39532251, 4.51192896, 6.54405967, 9.2382256 ,\n",
       "         8.89249209, 8.39590231, 9.20570753]),\n",
       "  array([4.85018295, 8.39532251, 4.51192896, 6.54405967, 9.2382256 ,\n",
       "         8.89249209, 8.39590231, 9.20570753]),\n",
       "  array([32974.22691955]),\n",
       "  array([32974.22691955])),\n",
       " (array([4.85018295, 8.39532251, 4.51192896, 6.54405967, 9.2382256 ,\n",
       "         8.89249209, 8.39590231, 9.20570753]),\n",
       "  array([4.85018295, 8.39532251, 4.51192896, 6.54405967, 9.2382256 ,\n",
       "         8.89249209, 8.39590231, 9.20570753]),\n",
       "  array([32974.22691955]),\n",
       "  array([32974.22691955])),\n",
       " (array([4.85018295, 8.39532251, 4.51192896, 6.54405967, 9.2382256 ,\n",
       "         8.89249209, 8.39590231, 9.20570753]),\n",
       "  array([4.85018295, 8.39532251, 4.51192896, 6.54405967, 9.2382256 ,\n",
       "         8.89249209, 8.39590231, 9.20570753]),\n",
       "  array([32974.22691955]),\n",
       "  array([32974.22691955])),\n",
       " (array([7.51240616, 6.89222388, 2.27433044, 4.54304472, 7.5555095 ,\n",
       "         9.23104571, 6.35526986, 2.10700777]),\n",
       "  array([7.51240616, 6.89222388, 2.27433044, 4.54304472, 7.5555095 ,\n",
       "         9.23104571, 6.35526986, 2.10700777]),\n",
       "  array([32790.12947708]),\n",
       "  array([32790.12947708])),\n",
       " (array([7.51240616, 6.89222388, 2.27433044, 4.54304472, 7.5555095 ,\n",
       "         9.23104571, 6.35526986, 2.10700777]),\n",
       "  array([7.51240616, 6.89222388, 2.27433044, 4.54304472, 7.5555095 ,\n",
       "         9.23104571, 6.35526986, 2.10700777]),\n",
       "  array([32790.12947708]),\n",
       "  array([32790.12947708])),\n",
       " (array([8.40079326, 9.3841775 , 2.31882667, 5.22013186, 6.65516209,\n",
       "         8.69986095, 6.19268974, 9.05128145]),\n",
       "  array([8.40079326, 9.3841775 , 2.31882667, 5.22013186, 6.65516209,\n",
       "         8.69986095, 6.19268974, 9.05128145]),\n",
       "  array([31404.31568233]),\n",
       "  array([31404.31568233])),\n",
       " (array([8.40079326, 9.3841775 , 2.31882667, 5.22013186, 6.65516209,\n",
       "         8.69986095, 6.19268974, 9.05128145]),\n",
       "  array([8.40079326, 9.3841775 , 2.31882667, 5.22013186, 6.65516209,\n",
       "         8.69986095, 6.19268974, 9.05128145]),\n",
       "  array([31404.31568233]),\n",
       "  array([31404.31568233])),\n",
       " (array([8.40079326, 9.3841775 , 2.31882667, 5.22013186, 6.65516209,\n",
       "         8.69986095, 6.19268974, 9.05128145]),\n",
       "  array([8.40079326, 9.3841775 , 2.31882667, 5.22013186, 6.65516209,\n",
       "         8.69986095, 6.19268974, 9.05128145]),\n",
       "  array([31404.31568233]),\n",
       "  array([31404.31568233])),\n",
       " (array([4.34722906, 7.37824988, 2.26491685, 9.36257865, 8.89383302,\n",
       "         6.9966811 , 6.60915278, 8.03253647]),\n",
       "  array([4.34722906, 7.37824988, 2.26491685, 9.36257865, 8.89383302,\n",
       "         6.9966811 , 6.60915278, 8.03253647]),\n",
       "  array([29782.34066008]),\n",
       "  array([29782.34066008]))]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(results, key = lambda x: x[2], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7537bebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[87504.62,\n",
       " 86722.18,\n",
       " 85846.05,\n",
       " 85234.52,\n",
       " 83528.12,\n",
       " 83442.09,\n",
       " 83051.34,\n",
       " 82927.4,\n",
       " 82061.53,\n",
       " 81642.69,\n",
       " 81555.23,\n",
       " 81538.36,\n",
       " 80338.0,\n",
       " 79837.12,\n",
       " 79274.52,\n",
       " 78784.51,\n",
       " 78464.02,\n",
       " 78285.78,\n",
       " 78227.84,\n",
       " 77779.3,\n",
       " 77117.16,\n",
       " 76251.66,\n",
       " 75869.35,\n",
       " 74482.89,\n",
       " 74264.98,\n",
       " 74121.92,\n",
       " 74057.05,\n",
       " 73939.99,\n",
       " 73631.16,\n",
       " 73446.17,\n",
       " 73263.34,\n",
       " 72485.31,\n",
       " 71832.66,\n",
       " 71412.88,\n",
       " 70886.62,\n",
       " 70830.75,\n",
       " 68788.69,\n",
       " 68580.09,\n",
       " 68412.84,\n",
       " 67842.77,\n",
       " 67582.01,\n",
       " 67541.22,\n",
       " 65967.9,\n",
       " 65755.58,\n",
       " 65196.87,\n",
       " 64191.2,\n",
       " 63832.05,\n",
       " 63545.63,\n",
       " 63428.37,\n",
       " 62995.52,\n",
       " 62259.07,\n",
       " 61916.03,\n",
       " 61777.55,\n",
       " 60676.16,\n",
       " 60241.04,\n",
       " 59576.45,\n",
       " 59528.58,\n",
       " 59376.38,\n",
       " 59242.72,\n",
       " 59079.92,\n",
       " 58941.78,\n",
       " 58933.1,\n",
       " 58280.82,\n",
       " 58009.89,\n",
       " 57964.61,\n",
       " 57829.19,\n",
       " 57613.95,\n",
       " 57492.59,\n",
       " 57476.48,\n",
       " 57130.39,\n",
       " 56982.9,\n",
       " 56945.66,\n",
       " 56933.59,\n",
       " 56623.36,\n",
       " 56583.86,\n",
       " 56483.61,\n",
       " 56466.14,\n",
       " 55940.92,\n",
       " 55933.92,\n",
       " 55512.09,\n",
       " 55372.77,\n",
       " 55176.56,\n",
       " 55084.65,\n",
       " 54923.63,\n",
       " 54917.07,\n",
       " 54591.75,\n",
       " 54481.37,\n",
       " 54169.0,\n",
       " 54082.5,\n",
       " 53435.33,\n",
       " 53361.03,\n",
       " 53131.57,\n",
       " 53128.57,\n",
       " 52277.82,\n",
       " 52040.86,\n",
       " 51484.24,\n",
       " 51478.34,\n",
       " 51216.0,\n",
       " 50891.45,\n",
       " 50145.55,\n",
       " 50091.75,\n",
       " 50014.9,\n",
       " 49986.26,\n",
       " 49868.83,\n",
       " 49796.77,\n",
       " 49490.61,\n",
       " 49161.92,\n",
       " 48776.66,\n",
       " 48273.97,\n",
       " 48261.59,\n",
       " 48190.71,\n",
       " 48098.7,\n",
       " 46953.95,\n",
       " 46524.35,\n",
       " 46129.22,\n",
       " 46091.66,\n",
       " 45922.62,\n",
       " 45878.44,\n",
       " 45864.03,\n",
       " 45782.82,\n",
       " 45501.43,\n",
       " 44826.27,\n",
       " 44633.94,\n",
       " 43917.88,\n",
       " 43852.49,\n",
       " 43735.25,\n",
       " 43498.45,\n",
       " 43223.52,\n",
       " 42834.68,\n",
       " 42826.96,\n",
       " 42712.16,\n",
       " 42488.39,\n",
       " 42392.09,\n",
       " 42310.96,\n",
       " 42216.71,\n",
       " 42126.63,\n",
       " 41955.81,\n",
       " 41604.7,\n",
       " 41575.52,\n",
       " 41272.68,\n",
       " 41209.06,\n",
       " 41014.12,\n",
       " 40838.39,\n",
       " 40674.69,\n",
       " 40365.63,\n",
       " 40312.21,\n",
       " 40240.8,\n",
       " 40218.37,\n",
       " 40209.09,\n",
       " 39934.32,\n",
       " 39898.93,\n",
       " 39893.78,\n",
       " 39812.22,\n",
       " 39772.36,\n",
       " 39632.97,\n",
       " 39455.15,\n",
       " 38696.92,\n",
       " 38631.77,\n",
       " 38479.91,\n",
       " 38288.45,\n",
       " 38272.51,\n",
       " 38228.54,\n",
       " 38203.33,\n",
       " 38061.4,\n",
       " 38055.51,\n",
       " 38007.75,\n",
       " 37963.37,\n",
       " 37868.46,\n",
       " 37774.8,\n",
       " 37664.28,\n",
       " 37555.24,\n",
       " 37259.05,\n",
       " 37199.73,\n",
       " 37090.28,\n",
       " 36968.19,\n",
       " 36848.17,\n",
       " 36297.46,\n",
       " 36190.71,\n",
       " 35755.04,\n",
       " 35681.61,\n",
       " 35386.52,\n",
       " 35125.81,\n",
       " 34622.34,\n",
       " 34621.07,\n",
       " 34553.53,\n",
       " 34098.0,\n",
       " 34050.94,\n",
       " 34024.41,\n",
       " 33497.77,\n",
       " 33448.64,\n",
       " 33214.96,\n",
       " 32969.1,\n",
       " 32915.28,\n",
       " 32312.23,\n",
       " 32187.64,\n",
       " 31592.12,\n",
       " 29418.82,\n",
       " 18493.71,\n",
       " 4246.804,\n",
       " 4182.584,\n",
       " 4169.862,\n",
       " 4146.092,\n",
       " 4085.169,\n",
       " 4028.038,\n",
       " 3919.829,\n",
       " 3914.767,\n",
       " 0.004902713,\n",
       " 0.004818215,\n",
       " 0.004691108,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df['Altitude'], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "14528868",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = [3.79774661, 2.50143278, 8.75329661, 8.87230654, 8.79869793,\n",
    "         3.59618521, 8.76162157, 8.74398984]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0981ef8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9999]], dtype=torch.float64, grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classif(torch.from_numpy(poly.fit_transform([best])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "8b0363a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interaction terms help marginally. \n",
    "#X_train, X_test = df.iloc[100:300, :-15], df.iloc[300:, :-15]\n",
    "#X_train, X_test = df.iloc[100:, :-15], df.iloc[:100, :-15]\n",
    "idxs = np.array(list(range(200, 400)) + list(range(100)))\n",
    "X_train, X_test = poly.fit_transform(df.iloc[idxs, :-15]), poly.fit_transform(df.iloc[100:200, :-15])\n",
    "#X_train, X_test = df.iloc[100:300, :-15], df.iloc[300:, :-15]\n",
    "\n",
    "# Stability level 1: cluster into flight time of 20 and 90.\n",
    "#Y_train, Y_test = df.iloc[:300, -1] > 90, df.iloc[300:, -1] > 90\n",
    "#Y_train, Y_test = df.iloc[100:, -1] > 90, df.iloc[:100, -1] > 90\n",
    "Y_train, Y_test = df.iloc[idxs, -1] > 90, df.iloc[100:200, -1] > 90\n",
    "#Y_train, Y_test = df.iloc[:300, -1] > 90, df.iloc[300:, -1] > 90\n",
    "\n",
    "reg = LR(penalty = 'l2')\n",
    "reg.fit(X_train, Y_train)\n",
    "sum(reg.predict(X_test) == Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "daf95079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PolynomialFeatures()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PolynomialFeatures()"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83492a37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
